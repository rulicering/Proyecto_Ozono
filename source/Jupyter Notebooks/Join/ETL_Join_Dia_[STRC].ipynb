{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [o3]- Proyecto Ozono - ETL_Join_Dia_[STRC]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [0] - Inicialización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/rulicering/BigData/spark-2.4.5-bin-hadoop2.7')\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import pandas as pandas\n",
    "from pyspark.sql.types import StructField,StringType,IntegerType,StructType,FloatType\n",
    "import re as reg\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JoinDia():\n",
    "    def __init__(self):\n",
    "        self.spark = SparkSession.builder.appName('join_hoy').getOrCreate()\n",
    "        self.spark.sparkContext.setLogLevel('ERROR')\n",
    "    \n",
    "    def process(self):\n",
    "        self.extraccion()\n",
    "        self.dar_grupo_clima_a_estaciones_aire()\n",
    "        self.merge_clima_aire()\n",
    "        self.incluir_calendario()\n",
    "        self.formato()\n",
    "        self.carga()\n",
    "        \n",
    "    def extraccion(self):\n",
    "        dia = (datetime.date.today() - datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "        df_aire = self.spark.read.csv(\"/home/rulicering/Datos_Proyecto_Ozono/Procesado/Contaminacion/Contaminacion_mediadia-\" + dia +\".csv\",inferSchema= True,header=True)\n",
    "        df_clima = self.spark.read.csv('/home/rulicering/Datos_Proyecto_Ozono/Procesado/Clima/Clima-' + dia +  '.csv',inferSchema= True,header=True)\n",
    "        df_estaciones = self.spark.read.csv(\"/home/rulicering/Datos_Proyecto_Ozono/Procesado/Estaciones/Estaciones-\" + dia +\".csv\",inferSchema= True,header=True)\n",
    "        df_calendario = self.spark.read.csv('/home/rulicering/Datos_Proyecto_Ozono/Procesado/Calendario/Calendario_2001-2020.csv',inferSchema= True,header=True)\n",
    "        \n",
    "        pd_aire = df_aire.drop(\"_c0\").toPandas()\n",
    "        pd_clima = df_clima.drop(\"_c0\").toPandas()\n",
    "        pd_estaciones = df_estaciones.drop(\"_c0\").toPandas()\n",
    "        pd_calendario = df_calendario.drop(\"_c0\").toPandas()\n",
    "        \n",
    "        #Estaciones\n",
    "        #None to NULO\n",
    "        pd_estaciones = pd_estaciones.replace(('None',None),np.nan)\n",
    "        #Columnas estaciones medicion - 2014\n",
    "        regex = reg.compile(\"E_AEMET_HOY\")\n",
    "        self.c_aemet_hoy = [elem for elem in list(filter(regex.search,df_estaciones.columns))]\n",
    "        \n",
    "        #Columnas estaciones medicion a string\n",
    "        for columna in self.c_aemet_hoy:\n",
    "            pd_estaciones[columna] = pd_estaciones[columna].astype(str)\n",
    "            \n",
    "        self.pd_estaciones = pd_estaciones\n",
    "        \n",
    "        #Aire\n",
    "        #None to NULO\n",
    "        pd_aire = pd_aire.replace(('None',None),np.nan)\n",
    "        #CODIGOS CORTOS A Strig\n",
    "        pd_aire[\"CODIGO_CORTO\"] = pd_aire[\"CODIGO_CORTO\"].astype(str)\n",
    "        pd_aire = pd_aire.sort_values(by=\"FECHA\")\n",
    "        print(\"Estaciones que miden datoss actuales de contaminación: \", pd_aire[\"CODIGO_CORTO\"].count())\n",
    "        self.pd_aire = pd_aire\n",
    "\n",
    "        #Clima\n",
    "        #None to NULO\n",
    "        pd_clima = pd_clima.replace(('None',None),np.nan)\n",
    "        #Listar las columnas que miden magnitudes\n",
    "        columnas_valoresmagnitudes = list(pd_clima.columns)[5:]\n",
    "        #Columnas magnitudes a float\n",
    "        for columna in columnas_valoresmagnitudes:\n",
    "            #Comas por puntos\n",
    "            pd_clima[columna]  =  [reg.sub(',','.',str(x)) for x in pd_clima[columna]]\n",
    "            # String to float\n",
    "            pd_clima[columna] = pd_clima[columna].astype(float)\n",
    "        pd_clima = pd_clima.sort_values(by=\"FECHA\")\n",
    "        self.pd_clima = pd_clima\n",
    "        \n",
    "        #Calendario\n",
    "        #None to NULO\n",
    "        pd_calendario = pd_calendario.replace(('None',None),np.nan)\n",
    "        self.pd_calendario = pd_calendario\n",
    "        \n",
    "    def dar_grupo_clima_a_estaciones_aire(self):\n",
    "        #Sacamos estaciones de aire y codigos de estaciones de clima asociadas\n",
    "        pd_estaciones_aire = self.pd_estaciones[self.pd_estaciones[\"MIDE_AIRE\"]>0]\n",
    "        #Nos quedamos con las columnas que queremos\n",
    "        c_agrupamiento = [\"CODIGO_CORTO\"] + self.c_aemet_hoy\n",
    "        pd_estaciones_aire = pd_estaciones_aire[c_agrupamiento]\n",
    "        #Unimos ambos datasets\n",
    "        pd_aire = self.pd_aire.merge(pd_estaciones_aire, on =[\"CODIGO_CORTO\"])\n",
    "        self.pd_datos_hoy = pd_aire\n",
    "        \n",
    "    def merge_clima_aire(self):\n",
    "        pd_datos_hoy = self.pd_datos_hoy\n",
    "        pd_clima = self.pd_clima\n",
    "        \n",
    "        columnas = list(pd_clima.columns) \n",
    "        c_info = columnas[:5]\n",
    "        c_magnitudes = columnas[5:]\n",
    "\n",
    "        #Asociamos cada columna de datos de clima (magnitud) a la estación de aire correspondiente.  \n",
    "        for magnitud in c_magnitudes:\n",
    "            cols = c_info.copy()\n",
    "            cols.append(magnitud)\n",
    "            pd_clima_magnitud_hoy = pd_clima[cols]\n",
    "\n",
    "            #HOY\n",
    "            pd_clima_magnitud_hoy = pd_clima_magnitud_hoy.rename(columns={\"CODIGO_CORTO\":\"E_AEMET_HOY_%s\"%magnitud})\n",
    "            pd_datos_hoy =pd_datos_hoy.merge(pd_clima_magnitud_hoy,on = [\"ANO\", \"MES\", \"DIA\",\"FECHA\",\"E_AEMET_HOY_%s\"%magnitud])\n",
    "            \n",
    "        self.pd_datos_hoy = pd_datos_hoy\n",
    "    def incluir_calendario(self):\n",
    "        self.pd_datos_hoy_y_calendario = self.pd_datos_hoy.merge(self.pd_calendario, on = \"FECHA\")\n",
    "        \n",
    "    def formato(self):\n",
    "        #Borramos las columnas utilizadas para relacionar estaciones de aire y clima\n",
    "        a_borrar = self.c_aemet_hoy\n",
    "        pd_datos_hoy = self.pd_datos_hoy_y_calendario.drop(columns = a_borrar)\n",
    "        \n",
    "        #Colocamos columnas\n",
    "        cols = pd_datos_hoy.columns.tolist()\n",
    "        cols = [cols[4]] + cols[0:4] +cols[-3:]+ cols[5:-3]\n",
    "        pd_datos_hoy = pd_datos_hoy[cols]\n",
    "        \n",
    "        pd_datos_hoy[\"CODIGO_CORTO\"] = pd_datos_hoy[\"CODIGO_CORTO\"].astype(int)\n",
    "        self.pd_datos_hoy = pd_datos_hoy\n",
    "        \n",
    "    def carga(self):\n",
    "        pd_datos_hoy = self.pd_datos_hoy\n",
    "        #EL join se ejecuta a las 2 am del dia siguiente. 1 día de diferencia\n",
    "        nuevo = (datetime.date.today() - datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "        anterior = (datetime.date.today() - datetime.timedelta(days=2)).strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        #BackUp\n",
    "        pd_datos_hoy.to_csv(\"/home/rulicering/Datos_Proyecto_Ozono/Procesado/Dato_Final/BackUp/Datos-Dia-\" + nuevo + \".csv\")\n",
    "        pd_datos_hoy.to_csv(\"/home/rulicering/Datos_Proyecto_Ozono/Procesado/Dato_Final/Datos-Dia-\" + nuevo + \".csv\")\n",
    "        print(\"[INFO] - Datos-Dia-\"+ nuevo+\".csv --- Created successfully\")\n",
    "        #Borrar la de ayer\n",
    "        try:\n",
    "            os.remove(\"/home/rulicering/Datos_Proyecto_Ozono/Procesado/Dato_Final/Datos-Dia-\" + anterior + \".csv\")\n",
    "            print(\"[INFO] - Datos-Dia-\" +  anterior + \".csv --- Removed successfully\")\n",
    "        except:\n",
    "            print(\"[ERROR] - Datos-Dia-\"+ anterior +\".csv --- Could not been removed\")\n",
    "            \n",
    "        #Inlcuir datos hoy en el conjunto total de datos (Dato Final)\n",
    "        pd_datos = pandas.read_csv('/home/rulicering/Datos_Proyecto_Ozono/Procesado/Dato_Final/Datos.csv')\n",
    "        pd_datos = pandas_datos.drop(columns = [\"Unnamed: 0\"])\n",
    "        pd_datos_final = pandas.concat([pd_datos,pd_datos_hoy])\n",
    "        \n",
    "        #BackUp\n",
    "        pd_datos_final.to_csv(\"/home/rulicering/Datos_Proyecto_Ozono/Procesado/Dato_Final/BackUp/Join_diario/Datos-\" + nuevo + \".csv\")\n",
    "        \n",
    "        pd_datos_final.to_csv(\"/home/rulicering/Datos_Proyecto_Ozono/Procesado/Dato_Final/Datos.csv\")\n",
    "        print(\"[INFO] - JOIN DATOS HOY + TOTAL - Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_dia = JoinDia()\n",
    "join_dia.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
