{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [o3]- Proyecto Ozono - Predictor_[STRC]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [0] - Inicialización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/rulicering/BigData/spark-2.4.5-bin-hadoop2.7')\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "import pandas as pd\n",
    "from pyspark.sql.types import StructField,StringType,IntegerType,StructType,FloatType\n",
    "import re as reg\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "#MlLib\n",
    "#from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "#Aux\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor():\n",
    "    def __init__(self):\n",
    "        self.spark = SparkSession.builder.appName('predictor_datos').getOrCreate()\n",
    "        self.spark.sparkContext.setLogLevel('ERROR')\n",
    "        \n",
    "    def process(self):\n",
    "        self.extraccion()\n",
    "        self.preparar_dato()\n",
    "        self._probabilidad_a_lluvia_presion_ayer_aire_a_null()\n",
    "        self._union_total_hoy()\n",
    "        self._añadir_contaminacion_ayer()\n",
    "        self.predictor_gbt()\n",
    "        self.carga()\n",
    "        \n",
    "    def extraccion(self):\n",
    "        ayer = (datetime.date.today() + datetime.timedelta(days = -1)).strftime(\"%Y-%m-%d\")\n",
    "        hoy = datetime.date.today().strftime(\"%Y-%m-%d\")\n",
    "        df_datos = self.spark.read.csv('/home/rulicering/Datos_Proyecto_Ozono/Procesado/Dato_Final/Datos.csv',inferSchema= True,header=True)\n",
    "        df_clima_prediccion = self.spark.read.csv(\"/home/rulicering/Datos_Proyecto_Ozono/Procesado/Clima/Clima_Prediccion-\"+ hoy + \".csv\",inferSchema= True,header=True)\n",
    "        df_calendario = self.spark.read.csv('/home/rulicering/Datos_Proyecto_Ozono/Procesado/Calendario/Calendario_2001-2020.csv',inferSchema= True,header=True)\n",
    "        \n",
    "        self.df_datos = df_datos.drop(\"_c0\")\n",
    "        self.df_clima_prediccion = df_clima_prediccion.drop(\"_c0\")\n",
    "        self.df_calendario = df_calendario.drop(\"_c0\")\n",
    "        \n",
    "        self.magnitudes= self.df_datos.columns[8:]\n",
    "        self.magnitudes_clima = self.df_datos.columns[-5:]\n",
    "        self.magnitudes_aire = self.df_datos.columns[8:-5]\n",
    "        \n",
    "        self.dic_clima = { \"VIENTO\":\"81\",\n",
    "                 \"DIRECCION\": \"82\",\n",
    "                 \"TEMPERATURA\": \"83\",\n",
    "                 \"PRESION\": \"87\",\n",
    "                 \"LLUVIA\":\"89\"\n",
    "        }\n",
    "        \n",
    "    def preparar_dato(self):\n",
    "        ayer = (datetime.date.today() + datetime.timedelta(days = -1)).strftime(\"%Y%m%d\")\n",
    "        hoy = datetime.date.today().strftime(\"%Y%m%d\")\n",
    "        \n",
    "        df_estaciones_aire = self.df_datos.filter(self.df_datos[\"FECHA\"]== ayer).select(\"CODIGO_CORTO\")\n",
    "        cod_estaciones_aire = [elem[0] for elem in df_estaciones_aire.collect()]\n",
    "        cod_estaciones_aire.sort()\n",
    "        self.cod_estaciones_aire = cod_estaciones_aire\n",
    "        \n",
    "        df_hoy = self.df_calendario.filter(self.df_calendario[\"FECHA\"]== hoy)\n",
    "\n",
    "        #Calendario + Magnitudes aire a null\n",
    "        for magnitud in self.magnitudes_aire:\n",
    "            df_hoy = df_hoy.withColumn(magnitud,F.lit(None))\n",
    "            \n",
    "        #Calendario + Prediccion clima\n",
    "        df_clima_hoy = df_hoy.join(self.df_clima_prediccion,on= \"FECHA\")\n",
    "        \n",
    "        #Estaciones cross datos clima y calendario\n",
    "        df_datos_hoy = df_estaciones_aire.crossJoin(df_clima_hoy)\n",
    "        \n",
    "        cols = df_datos_hoy.columns\n",
    "        cols = cols[0:1] + cols[19:22]+ cols[1:5]+ cols[5:19] + cols[22:]\n",
    "        self.df_datos_hoy = df_datos_hoy.select(cols)\n",
    "        \n",
    "        \n",
    "    def _probabilidad_a_lluvia_presion_ayer_aire_a_null(self):\n",
    "        \n",
    "        df_datos = self.df_datos\n",
    "        df_datos_hoy = self.df_datos_hoy\n",
    "        cod_estaciones_aire = self.cod_estaciones_aire\n",
    "        dic_clima = self.dic_clima\n",
    "        df_clima_prediccion = self.df_clima_prediccion\n",
    "        \n",
    "        mes_dia_min = (datetime.date.today() +  datetime.timedelta(days = -10)).strftime(\"%m%d\")\n",
    "        mes_dia_max = (datetime.date.today() +  datetime.timedelta(days = 10)).strftime(\"%m%d\")\n",
    "        df_historial = df_datos.filter((df_datos[\"FECHA\"]%1000 >= mes_dia_min) & (df_datos[\"FECHA\"]%1000 <= mes_dia_max))\n",
    "        df_datos_hoy = df_datos_hoy.drop('%' + dic_clima[\"LLUVIA\"])\n",
    "        l_df = []\n",
    "        for estacion in cod_estaciones_aire:\n",
    "            df_datos_hoy_estacion = df_datos_hoy.filter(df_datos_hoy[\"CODIGO_CORTO\"]==estacion)\n",
    "            aux = df_historial.filter(df_historial[\"CODIGO_CORTO\"]== estacion).select(\"FECHA\",dic_clima[\"PRESION\"],dic_clima[\"LLUVIA\"]).na.drop()\n",
    "            #Precipitacions\n",
    "            prob_lluvia_hoy = df_clima_prediccion.select(\"%\" +dic_clima[\"LLUVIA\"]).collect()[0][0]\n",
    "            prec = 0\n",
    "            if(float(prob_lluvia_hoy) > 50):\n",
    "                try:\n",
    "                    prec = aux.filter(aux[dic_clima[\"LLUVIA\"]] >0).select(dic_clima[\"LLUVIA\"]).groupBy().mean().collect()[0][0]\n",
    "                except:\n",
    "                    print(\"[WARN]: No hay lluvias historicas en ese rango de fechas\")\n",
    "            df_datos_hoy_estacion = df_datos_hoy_estacion.withColumn(dic_clima[\"LLUVIA\"],F.lit(prec))\n",
    "\n",
    "            #Presion\n",
    "            ayer = (datetime.date.today() + datetime.timedelta(days= -1)).strftime(\"%Y%m%d\")\n",
    "            presion_ayer = aux.filter(aux[\"FECHA\"]==ayer).select(dic_clima[\"PRESION\"]).collect()[0][0]\n",
    "            df_datos_hoy_estacion = df_datos_hoy_estacion.withColumn(dic_clima[\"PRESION\"],F.lit(presion_ayer))\n",
    "\n",
    "            l_df.append(df_datos_hoy_estacion)\n",
    "\n",
    "        df_datos_hoy = l_df[0]\n",
    "        for i in range(1,len(l_df)):\n",
    "            df_datos_hoy = df_datos_hoy.union(l_df[i])\n",
    "            \n",
    "        self.df_datos_hoy = df_datos_hoy\n",
    "    \n",
    "    \n",
    "    def _union_total_hoy(self):\n",
    "        self.df_datos= self.df_datos.union(self.df_datos_hoy)\n",
    "        \n",
    "    def _añadir_contaminacion_ayer(self):\n",
    "        df_datos = self.df_datos\n",
    "        ventana = Window.partitionBy(\"CODIGO_CORTO\").orderBy(\"FECHA\")\n",
    "        for magnitud in self.magnitudes_aire:\n",
    "            df_datos = df_datos.withColumn(\"A_%s\"%magnitud, F.lag(magnitud,1,None).over(ventana))\n",
    "        self.df_datos = df_datos\n",
    "        \n",
    "    def predictor_gbt(self):\n",
    "        hoy = datetime.date.today().strftime(\"%Y%m%d\")\n",
    "        df_datos = self.df_datos.cache()\n",
    "        magnitudes_clima = self.magnitudes_clima\n",
    "        magnitudes_aire = self.magnitudes_aire\n",
    "        \n",
    "        cols_comunes = df_datos.columns[0:8] + magnitudes_clima\n",
    "        \n",
    "        l_predicciones = []\n",
    "        for magnitud in magnitudes_aire:\n",
    "            print(\"=\"*20, magnitud, \"=\"*20)\n",
    "            cols_comunes = df_datos.columns[0:8] + magnitudes_clima\n",
    "            cols_features = cols_comunes + [\"A_%s\"%magnitud]\n",
    "\n",
    "            #Limpiamos las filas con el dato para esa magnitud a Null\n",
    "            cols_y_magnitud = cols_features + [magnitud]\n",
    "            df_datos_magnitud_calculados = df_datos.filter(df_datos[\"FECHA\"] <hoy).select(cols_y_magnitud).na.drop().cache()\n",
    "            df_datos_magnitud_hoy = df_datos.filter(df_datos[\"FECHA\"] == hoy).select(cols_y_magnitud).na.drop(subset = \"A_%s\"%magnitud).cache()\n",
    "            #df_datos_magnitud = df_datos_magnitud_calculados.union(df_datos_magnitud_hoy)\n",
    "\n",
    "            #Assembles to create features column\n",
    "            assembler = VectorAssembler(inputCols = cols_features, outputCol = \"F_%s\" % magnitud)\n",
    "            data_assembled = assembler.transform(df_datos_magnitud_calculados)\n",
    "            data_to_predict_assembled = assembler.transform(df_datos_magnitud_hoy)\n",
    "\n",
    "            #Seleccionamos las filas que vamos a utilizar\n",
    "            trainingData = data_assembled.select(\"CODIGO_CORTO\",\"F_%s\" %magnitud, magnitud)\n",
    "            data_to_predict = data_to_predict_assembled.select(\"CODIGO_CORTO\",\"F_%s\" %magnitud, magnitud)\n",
    "\n",
    "            # Train a GBT model.\n",
    "            gbt = GBTRegressor(featuresCol=\"F_%s\" % magnitud, labelCol=magnitud,maxIter=20,predictionCol=\"P_%s\" %magnitud)\n",
    "\n",
    "            # Train model.  This also runs the indexer.\n",
    "            model = gbt.fit(trainingData)\n",
    "\n",
    "            # Make predictions.\n",
    "            predictions = model.transform(data_to_predict)\n",
    "\n",
    "            # Select example rows to display\n",
    "            predictions.select(\"CODIGO_CORTO\",\"P_%s\" %magnitud,\"F_%s\" % magnitud).show()\n",
    "            l_predicciones.append(predictions)\n",
    "        \n",
    "        df_prediccion = l_predicciones[0]\n",
    "        for i in range(1,len(l_predicciones)):\n",
    "            df_prediccion = df_prediccion.join(l_predicciones[i],on= \"CODIGO_CORTO\",how='outer')\n",
    "        pd_prediccion = df_prediccion.toPandas()\n",
    "        \n",
    "        #Formato\n",
    "        cols = pd_prediccion.columns.tolist()\n",
    "        regex = reg.compile(\"P_\")\n",
    "        cols_predicciones = [elem for elem in list(filter(regex.search,cols))]\n",
    "        cols = cols[0:1]+cols_predicciones\n",
    "        self.pd_prediccion = pd_prediccion[cols]\n",
    "    \n",
    "        \n",
    "    def carga(self):\n",
    "        pd_prediccion = self.pd_prediccion\n",
    "        \n",
    "        ayer = (datetime.date.today() + datetime.timedelta(days = -1)).strftime(\"%Y-%m-%d\")\n",
    "        hoy = datetime.date.today().strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        #BackUp\n",
    "        pd_prediccion.to_csv(\"/home/rulicering/Datos_Proyecto_Ozono/Procesado/Predicciones/BackUp/Prediccion-\" + hoy + \".csv\")\n",
    "        pd_prediccion.to_csv(\"/home/rulicering/Datos_Proyecto_Ozono/Procesado/Predicciones/Prediccion-\" + hoy + \".csv\")\n",
    "        print(\"[INFO] - Prediccion-\" +  hoy +\".csv --- Generated successfully\")\n",
    "        \n",
    "        #Borrar la de ayer\n",
    "        try:\n",
    "            os.remove(\"/home/rulicering/Datos_Proyecto_Ozono/Procesado/Predicciones/Prediccion-\" + ayer + \".csv\")\n",
    "            print(\"[INFO] - Prediccion-\" + ayer + \".csv --- Removed successfully\")\n",
    "        except:\n",
    "            print(\"[ERROR] - Prediccion-\" + ayer + \".csv --- Could not been removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== 1 ====================\n",
      "+------------+------------------+--------------------+\n",
      "|CODIGO_CORTO|               P_1|                 F_1|\n",
      "+------------+------------------+--------------------+\n",
      "|          40|3.8392476137311693|[40.0,2020.0,5.0,...|\n",
      "|          57| 5.941401134743733|[57.0,2020.0,5.0,...|\n",
      "|          17| 8.831543372893135|[17.0,2020.0,5.0,...|\n",
      "|          35| 5.032232230262039|[35.0,2020.0,5.0,...|\n",
      "|           4|3.8336227675508994|[4.0,2020.0,5.0,2...|\n",
      "|           8|7.9053632810615255|[8.0,2020.0,5.0,2...|\n",
      "|          38| 5.941401134743733|[38.0,2020.0,5.0,...|\n",
      "|          24| 4.900453439208006|[24.0,2020.0,5.0,...|\n",
      "|          18|7.9023001123335455|[18.0,2020.0,5.0,...|\n",
      "|          36| 5.998300021323876|[36.0,2020.0,5.0,...|\n",
      "+------------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#EJECUTAR\n",
    "predictor = Predictor()\n",
    "predictor.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
