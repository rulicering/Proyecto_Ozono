{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [o3] - Proyecto Ozono - ETL_Clima_(2001 -202004)  -v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [INFO]\n",
    "    \n",
    "       AEMET Y AYUNT -> DATOS A MES CERRADO\n",
    "       \n",
    "       DATOS AEMET -> 2001 - ACTUALIDAD \n",
    "       \n",
    "       AYUNT -> 2019 - ACTUALIDAD \n",
    "       \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    0. Inicialización\n",
    "    1. Datos\n",
    "        1.0 Carga fichero Estaciones\n",
    "        1.1 Lista magnitudes \n",
    "        1.2 ----------------------- AEMET -----------------------\n",
    "            1.2.0 Codegen + API\n",
    "            1.2.1 [FUNCION] -  Formateo datos\n",
    "            1.2.2 [FUNCIONES] - Request datos\n",
    "            1.2.3 _______ 2001-2018 _______\n",
    "                1.2.3.0 Estaciones \n",
    "                1.2.3.1 Fechas\n",
    "                1.2.3.2 Obtenemos los datos\n",
    "            1.2.4 _______ 2019-NOW ________\n",
    "                1.2.4.0 Estaciones\n",
    "                1.2.4.1 Fechas [20190101 - 2020 Ultimo mes cerrado]\n",
    "                1.2.4.2 Obtenemos los datos\n",
    "            1.2.5 Union\n",
    "            1.2.6 Columnas -> ANO,MES,DIA,FECHA\n",
    "            1.2.7 Columnas -> avg(Temp), avg(Pres)\n",
    "            1.2.8 Rename\n",
    "            1.2.9 Select\n",
    "            1.2.10 \"None\" a NULO\n",
    "            1.2.11 Types\n",
    "        1.3 ----------------------- AYUNTAMIENTO -----------------------\n",
    "            1.3.0 Obtenemos los datos\n",
    "            1.3.1 Estaciones\n",
    "            1.3.2 Filtar -> ESTACIONES UTILIZADAS\n",
    "            1.3.3 Select\n",
    "            1.3.4 Formato\n",
    "            1.3.5 Select -> [ESTACION,ANO,MES,DIA,FECHA,+MAGNITUDES]\n",
    "    2. Union AYUNT + AEMET\n",
    "    3. Formato\n",
    "        3.1 89-PRECIPITACION == \"IP\" == Inapreciable -> 0\n",
    "        3.2 Rename\n",
    "    4. Export\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [0] - Inicialización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import swagger_client\n",
    "from swagger_client.rest import ApiException\n",
    "from pprint import pprint\n",
    "import datetime\n",
    "import findspark\n",
    "findspark.init('/home/rulicering/BigData/spark-2.4.5-bin-hadoop2.7')\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import re as reg\n",
    "import collections\n",
    "import json\n",
    "from pyspark.sql.types import StructField,StringType,IntegerType,StructType,FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('clima').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [1] -  Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"/home/rulicering/Datos_Proyecto_Ozono/Credenciales/Credenciales.json\")\n",
    "credenciales = json.load(f)\n",
    "AEMET_API_KEY = credenciales[\"aemet\"][\"api_key\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1.0] - Carga fichero Estaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_estaciones = spark.read.csv(\"/home/rulicering/Datos_Proyecto_Ozono/Procesado/Estaciones/Estaciones.csv\",inferSchema= True, header= True)\n",
    "#Fuerzo que se ejecute para que luego al filtrar no tenga que volver a leer el csv\n",
    "df_estaciones = spark.createDataFrame(df_estaciones.toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1.1] - Lista magnitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = reg.compile(\"E_\\d\\d\")\n",
    "magnitudes = [elem[2:] for elem in list(filter(regex.search,df_estaciones.columns))]\n",
    "#magnitudes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1.2]  ----------------------- AEMET -----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    81 - VELOCIDAD VIENTO\n",
    "    82 - DIR. DE VIENTO\n",
    "    83 - TEMPERATURA \n",
    "    87 - PRESION BARIOMETRICA\n",
    "    89 - PRECIPITACIÓN    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.2.0] - Codegen + API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = swagger_client.Configuration()\n",
    "configuration.api_key['api_key'] = AEMET_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#api_instance = swagger_client.AvisosCapApi(swagger_client.ApiClient(configuration))\n",
    "api_observacion = swagger_client.ObservacionConvencionalApi(swagger_client.ApiClient(configuration))\n",
    "master_api_instance = swagger_client.MaestroApi(swagger_client.ApiClient(configuration))\n",
    "api_valores = swagger_client.ValoresClimatologicosApi(swagger_client.ApiClient(configuration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.2.1] - [FUNCION] -  Formateo datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_sparkdf(data):\n",
    "    #Encoding \"ISO-8859\"\n",
    "    data_v = data.decode(encoding ='ISO-8859-15')\n",
    "    data_v0 = data_v\n",
    "    # Clean the data\n",
    "    # Step 0 \n",
    "    for i in range(20):\n",
    "        if(data_v0[i]=='{'):\n",
    "            data_v0 = data_v0[i:]\n",
    "    for i in range(20):\n",
    "        if(data_v0[-i]=='}'):\n",
    "            data_v0 = data_v0[:-i+1]\n",
    "    # Step 1     \n",
    "    data_v1 = data_v0\n",
    "    data_v1 = data_v1.replace(\"\\n\", \"\")\n",
    "    \n",
    "    # Step 2\n",
    "    data_v2 = data_v1.replace(\"},\",\"}},\")\n",
    "    \n",
    "    # Step 3\n",
    "    patron =['\\s\\s','\\s\"','\"\\s','\\s{']\n",
    "    replace = [' ','\"','\"','{']\n",
    "    \n",
    "    data_v3 = data_v2\n",
    "    for i in range(len(patron)):\n",
    "        data_v3 = reg.sub(patron[i],replace[i],data_v3)\n",
    "\n",
    "    # Step 4\n",
    "    data_v4 = data_v3.replace(\"\\\",\\\"\",\"\\\";\\\"\")\n",
    "    \n",
    "    # Step 5\n",
    "    data_cleaned = data_v4.split(\"},\")\n",
    "\n",
    "    # String to List of dictionaries\n",
    "    diccionarios = []\n",
    "    for fila in data_cleaned:\n",
    "        #print(fila)\n",
    "        keys = []\n",
    "        values = []\n",
    "        for pareja in fila[1:-1].split(';'):\n",
    "            #print(\"Pareja= \",pareja)\n",
    "            elems =pareja.split(':')\n",
    "            #print(\"Elementos= \",elems)\n",
    "            keys.append(elems[0][1:-1])\n",
    "            values.append(elems[1][1:-1])\n",
    "        diccionarios.append(dict(zip(keys,values)))\n",
    "\n",
    "    # Schema for the new DF\n",
    "    data_schema = [StructField('altitud',StringType(), True), #Tercer argumento = nullable\n",
    "                   StructField('dir', StringType(), True),\n",
    "                   StructField('fecha', StringType(), True),\n",
    "                   StructField('horaPresMax', StringType(), True),\n",
    "                   StructField('horaPresMin', StringType(), True),\n",
    "                   StructField('horaracha', StringType(), True),\n",
    "                   StructField('horatmax', StringType(), True),\n",
    "                   StructField('horatmin',StringType(), True), #Tercer argumento = nullable\n",
    "                   StructField('indicativo', StringType(), True),\n",
    "                   StructField('nombre', StringType(), True),\n",
    "                   StructField('prec', StringType(), True),\n",
    "                   StructField('presMax', StringType(), True),\n",
    "                   StructField('presMin',StringType(), True), #Tercer argumento = nullable\n",
    "                   StructField('provincia', StringType(), True),\n",
    "                   StructField('racha', StringType(), True),\n",
    "                   StructField('sol', StringType(), True),\n",
    "                   StructField('tmax', StringType(), True),\n",
    "                   StructField('tmin', StringType(), True),\n",
    "                   StructField('velmedia', StringType(), True)\n",
    "                  ]\n",
    "    # Create and return the new DF\n",
    "    return spark.createDataFrame(diccionarios,schema = StructType(data_schema))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.2.2]  [FUNCIONES] - Request datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def req_to_df(codigo,fecha_ini,fecha_fin):\n",
    "    print(\"CODIGO: \", codigo, \"FECHAS\", fecha_ini,fecha_fin)\n",
    "    try:\n",
    "        api_response = api_valores.climatologas_diarias_(fecha_ini, fecha_fin,codigo)\n",
    "        pprint(api_response)\n",
    "    except ApiException as e:\n",
    "        print(\"Exception: %s\\n\" % e)\n",
    "    r = requests.get(api_response.datos)\n",
    "    data = r.content\n",
    "    df_aemet = data_to_sparkdf(data)\n",
    "    print(\"OK\")\n",
    "    \n",
    "    return df_aemet.select('fecha','indicativo','dir','prec','presMax','presMin','tmax','tmin','velmedia')\n",
    "    # Las estaciones del ayunt no tienen datos de insolacion (sol)\n",
    "    #return df_aemet.select('fecha','indicativo','dir','prec','presMax','presMin','sol','tmax','tmin','velmedia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datos_aemet(codigos_estaciones,fecha_ini,fecha_fin):\n",
    "    lista_df =[]\n",
    "    for codigo in codigos_estaciones:\n",
    "        lista_df.append(req_to_df(codigo,fecha_ini,fecha_fin))\n",
    "    #Unimos\n",
    "    df = lista_df[0]\n",
    "    for i in range(1,len(lista_df)):\n",
    "        df = df.union(lista_df[i])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.2.3]  _______ 2001-2018 _______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [1.2.3.0] - Estaciones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_estaciones_aemet = df_estaciones.filter(df_estaciones[\"U_AEMET\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_estaciones_aemet = [elem[0] for elem in df_estaciones_aemet.select(\"CODIGO_CORTO\").collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3129', '3194U', '3195', '3200']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cod_estaciones_aemet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [1.2.3.1] -  Fechas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_datos():\n",
    "    pares_anos = [(2001,2004),(2005,2008),(2009,2012),(2013,2016),(2017,2018)]\n",
    "    l_df = []\n",
    "    for par in pares_anos:\n",
    "        fecha_ini = datetime.date(par[0],1,1)\n",
    "        fecha_fin = datetime.date(par[1],12,31)\n",
    "\n",
    "        formato= \"%Y-%m-%dT%H:%M:%SUTC\"\n",
    "\n",
    "        fecha_ini_str = fecha_ini.strftime(formato)\n",
    "        fecha_fin_str = fecha_fin.strftime(formato)\n",
    "\n",
    "        df = datos_aemet(cod_estaciones_aemet,fecha_ini_str,fecha_fin_str)\n",
    "        l_df.append(df)\n",
    "    df = l_df[0]\n",
    "    for i in range(1,len(l_df)):\n",
    "        df = df.union(l_df[i])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [1.2.3.2] -  Obtenemos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CODIGO:  3129 FECHAS 2001-01-01T00:00:00UTC 2004-12-31T00:00:00UTC\n",
      "{'datos': 'https://opendata.aemet.es/opendata/sh/5a5d054e',\n",
      " 'descripcion': 'exito',\n",
      " 'estado': 200,\n",
      " 'metadatos': 'https://opendata.aemet.es/opendata/sh/b3aa9d28'}\n",
      "OK\n",
      "CODIGO:  3194U FECHAS 2001-01-01T00:00:00UTC 2004-12-31T00:00:00UTC\n",
      "{'datos': 'https://opendata.aemet.es/opendata/sh/db62fd96',\n",
      " 'descripcion': 'exito',\n",
      " 'estado': 200,\n",
      " 'metadatos': 'https://opendata.aemet.es/opendata/sh/b3aa9d28'}\n",
      "OK\n",
      "CODIGO:  3195 FECHAS 2001-01-01T00:00:00UTC 2004-12-31T00:00:00UTC\n",
      "{'datos': 'https://opendata.aemet.es/opendata/sh/a90bcc8b',\n",
      " 'descripcion': 'exito',\n",
      " 'estado': 200,\n",
      " 'metadatos': 'https://opendata.aemet.es/opendata/sh/b3aa9d28'}\n",
      "OK\n",
      "CODIGO:  3200 FECHAS 2001-01-01T00:00:00UTC 2004-12-31T00:00:00UTC\n",
      "{'datos': 'https://opendata.aemet.es/opendata/sh/c3353d54',\n",
      " 'descripcion': 'exito',\n",
      " 'estado': 200,\n",
      " 'metadatos': 'https://opendata.aemet.es/opendata/sh/b3aa9d28'}\n",
      "OK\n",
      "CODIGO:  3129 FECHAS 2005-01-01T00:00:00UTC 2008-12-31T00:00:00UTC\n",
      "{'datos': 'https://opendata.aemet.es/opendata/sh/2e601bed',\n",
      " 'descripcion': 'exito',\n",
      " 'estado': 200,\n",
      " 'metadatos': 'https://opendata.aemet.es/opendata/sh/b3aa9d28'}\n",
      "OK\n",
      "CODIGO:  3194U FECHAS 2005-01-01T00:00:00UTC 2008-12-31T00:00:00UTC\n",
      "{'datos': 'https://opendata.aemet.es/opendata/sh/0b33e679',\n",
      " 'descripcion': 'exito',\n",
      " 'estado': 200,\n",
      " 'metadatos': 'https://opendata.aemet.es/opendata/sh/b3aa9d28'}\n",
      "OK\n",
      "CODIGO:  3195 FECHAS 2005-01-01T00:00:00UTC 2008-12-31T00:00:00UTC\n",
      "{'datos': 'https://opendata.aemet.es/opendata/sh/4fb49caa',\n",
      " 'descripcion': 'exito',\n",
      " 'estado': 200,\n",
      " 'metadatos': 'https://opendata.aemet.es/opendata/sh/b3aa9d28'}\n",
      "OK\n",
      "CODIGO:  3200 FECHAS 2005-01-01T00:00:00UTC 2008-12-31T00:00:00UTC\n",
      "{'datos': 'https://opendata.aemet.es/opendata/sh/3710cb56',\n",
      " 'descripcion': 'exito',\n",
      " 'estado': 200,\n",
      " 'metadatos': 'https://opendata.aemet.es/opendata/sh/b3aa9d28'}\n",
      "OK\n",
      "CODIGO:  3129 FECHAS 2009-01-01T00:00:00UTC 2012-12-31T00:00:00UTC\n",
      "{'datos': 'https://opendata.aemet.es/opendata/sh/3f9152f3',\n",
      " 'descripcion': 'exito',\n",
      " 'estado': 200,\n",
      " 'metadatos': 'https://opendata.aemet.es/opendata/sh/b3aa9d28'}\n",
      "OK\n",
      "CODIGO:  3194U FECHAS 2009-01-01T00:00:00UTC 2012-12-31T00:00:00UTC\n",
      "{'datos': 'https://opendata.aemet.es/opendata/sh/a4d9d08c',\n",
      " 'descripcion': 'exito',\n",
      " 'estado': 200,\n",
      " 'metadatos': 'https://opendata.aemet.es/opendata/sh/b3aa9d28'}\n",
      "OK\n",
      "CODIGO:  3195 FECHAS 2009-01-01T00:00:00UTC 2012-12-31T00:00:00UTC\n",
      "{'datos': 'https://opendata.aemet.es/opendata/sh/f55bd19c',\n",
      " 'descripcion': 'exito',\n",
      " 'estado': 200,\n",
      " 'metadatos': 'https://opendata.aemet.es/opendata/sh/b3aa9d28'}\n",
      "OK\n",
      "CODIGO:  3200 FECHAS 2009-01-01T00:00:00UTC 2012-12-31T00:00:00UTC\n",
      "{'datos': 'https://opendata.aemet.es/opendata/sh/25f5004c',\n",
      " 'descripcion': 'exito',\n",
      " 'estado': 200,\n",
      " 'metadatos': 'https://opendata.aemet.es/opendata/sh/b3aa9d28'}\n",
      "OK\n",
      "CODIGO:  3129 FECHAS 2013-01-01T00:00:00UTC 2016-12-31T00:00:00UTC\n",
      "{'datos': 'https://opendata.aemet.es/opendata/sh/031e4bde',\n",
      " 'descripcion': 'exito',\n",
      " 'estado': 200,\n",
      " 'metadatos': 'https://opendata.aemet.es/opendata/sh/b3aa9d28'}\n",
      "OK\n",
      "CODIGO:  3194U FECHAS 2013-01-01T00:00:00UTC 2016-12-31T00:00:00UTC\n",
      "{'datos': 'https://opendata.aemet.es/opendata/sh/509c75fe',\n",
      " 'descripcion': 'exito',\n",
      " 'estado': 200,\n",
      " 'metadatos': 'https://opendata.aemet.es/opendata/sh/b3aa9d28'}\n",
      "OK\n",
      "CODIGO:  3195 FECHAS 2013-01-01T00:00:00UTC 2016-12-31T00:00:00UTC\n",
      "{'datos': 'https://opendata.aemet.es/opendata/sh/34f69ecd',\n",
      " 'descripcion': 'exito',\n",
      " 'estado': 200,\n",
      " 'metadatos': 'https://opendata.aemet.es/opendata/sh/b3aa9d28'}\n",
      "OK\n",
      "CODIGO:  3200 FECHAS 2013-01-01T00:00:00UTC 2016-12-31T00:00:00UTC\n",
      "{'datos': 'https://opendata.aemet.es/opendata/sh/212026be',\n",
      " 'descripcion': 'exito',\n",
      " 'estado': 200,\n",
      " 'metadatos': 'https://opendata.aemet.es/opendata/sh/b3aa9d28'}\n",
      "OK\n",
      "CODIGO:  3129 FECHAS 2017-01-01T00:00:00UTC 2018-12-31T00:00:00UTC\n",
      "{'datos': 'https://opendata.aemet.es/opendata/sh/093ade28',\n",
      " 'descripcion': 'exito',\n",
      " 'estado': 200,\n",
      " 'metadatos': 'https://opendata.aemet.es/opendata/sh/b3aa9d28'}\n",
      "OK\n",
      "CODIGO:  3194U FECHAS 2017-01-01T00:00:00UTC 2018-12-31T00:00:00UTC\n",
      "{'datos': 'https://opendata.aemet.es/opendata/sh/926a68f7',\n",
      " 'descripcion': 'exito',\n",
      " 'estado': 200,\n",
      " 'metadatos': 'https://opendata.aemet.es/opendata/sh/b3aa9d28'}\n",
      "OK\n",
      "CODIGO:  3195 FECHAS 2017-01-01T00:00:00UTC 2018-12-31T00:00:00UTC\n",
      "{'datos': 'https://opendata.aemet.es/opendata/sh/96f32a6b',\n",
      " 'descripcion': 'exito',\n",
      " 'estado': 200,\n",
      " 'metadatos': 'https://opendata.aemet.es/opendata/sh/b3aa9d28'}\n",
      "OK\n",
      "CODIGO:  3200 FECHAS 2017-01-01T00:00:00UTC 2018-12-31T00:00:00UTC\n",
      "{'datos': 'https://opendata.aemet.es/opendata/sh/90899e58',\n",
      " 'descripcion': 'exito',\n",
      " 'estado': 200,\n",
      " 'metadatos': 'https://opendata.aemet.es/opendata/sh/b3aa9d28'}\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "df_aemet_01_18 = obtener_datos()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.2.4]  _______ 2019-NOW _______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [1.2.4.0] - Estaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_estaciones_aemet_19 = df_estaciones.filter(df_estaciones[\"MIDE_CLIMA_AEMET\"]>0).filter(df_estaciones[\"U_TODAS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_estaciones_aemet_19 = [elem[0] for elem in df_estaciones_aemet_19.select(\"CODIGO_CORTO\").collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3129', '3194U', '3195']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cod_estaciones_aemet_19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [1.2.4.1] - Fechas [20190101 - 2020 Ultimo mes cerrado]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fechas inicio y fecha fin datos\n",
    "fecha_ini = datetime.date(2019,1,1)\n",
    "ultimo_dia_mes_cerrado = datetime.date.today().replace(day=1) - datetime.timedelta(days=1)\n",
    "fecha_fin = ultimo_dia_mes_cerrado\n",
    "formato= \"%Y-%m-%dT%H:%M:%SUTC\"\n",
    "\n",
    "fecha_ini_str = fecha_ini.strftime(formato)\n",
    "fecha_fin_str = fecha_fin.strftime(formato)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [1.2.4.2] - Obtenemos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CODIGO:  3129 FECHAS 2019-01-01T00:00:00UTC 2020-04-30T00:00:00UTC\n",
      "{'datos': 'https://opendata.aemet.es/opendata/sh/3e348db2',\n",
      " 'descripcion': 'exito',\n",
      " 'estado': 200,\n",
      " 'metadatos': 'https://opendata.aemet.es/opendata/sh/b3aa9d28'}\n",
      "OK\n",
      "CODIGO:  3194U FECHAS 2019-01-01T00:00:00UTC 2020-04-30T00:00:00UTC\n",
      "{'datos': 'https://opendata.aemet.es/opendata/sh/b45f07bf',\n",
      " 'descripcion': 'exito',\n",
      " 'estado': 200,\n",
      " 'metadatos': 'https://opendata.aemet.es/opendata/sh/b3aa9d28'}\n",
      "OK\n",
      "CODIGO:  3195 FECHAS 2019-01-01T00:00:00UTC 2020-04-30T00:00:00UTC\n",
      "{'datos': 'https://opendata.aemet.es/opendata/sh/2384a975',\n",
      " 'descripcion': 'exito',\n",
      " 'estado': 200,\n",
      " 'metadatos': 'https://opendata.aemet.es/opendata/sh/b3aa9d28'}\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "df_aemet_19 = datos_aemet(cod_estaciones_aemet_19,fecha_ini_str,fecha_fin_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.2.5] -  Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_aemet = df_aemet_01_18.union(df_aemet_19).orderBy(\"fecha\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.2.6] -Columnas -> ANO,MES,DIA,FECHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aemet = df_aemet.withColumn(\"ANO\",df_aemet[\"fecha\"][0:4])\n",
    "df_aemet = df_aemet.withColumn(\"MES\",df_aemet[\"fecha\"][6:2])\n",
    "df_aemet = df_aemet.withColumn(\"DIA\",df_aemet[\"fecha\"][9:2])\n",
    "df_aemet = df_aemet.withColumn(\"FECHA\",F.concat(df_aemet[\"fecha\"][0:4],df_aemet[\"fecha\"][6:2],df_aemet[\"fecha\"][9:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.2.7] - Columnas -> avg(Temp), avg(Pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_aemet = df_aemet.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Cambias comas por puntos\n",
    "pd_aemet[\"presMax\"]  =  [reg.sub(',','.',str(x)) for x in pd_aemet[\"presMax\"]]\n",
    "pd_aemet[\"presMin\"]  =  [reg.sub(',','.',str(x)) for x in pd_aemet[\"presMin\"]]\n",
    "pd_aemet[\"tmax\"]  =  [reg.sub(',','.',str(x)) for x in pd_aemet[\"tmax\"]]\n",
    "pd_aemet[\"tmin\"]  =  [reg.sub(',','.',str(x)) for x in pd_aemet[\"tmin\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def media(vals):\n",
    "    validos = 0\n",
    "    nulos = 0\n",
    "    media = 0\n",
    "    for i in range(len(vals)):\n",
    "        if(vals[i] != 'None')or(vals[i] is None):\n",
    "            validos += 1\n",
    "            media += float(vals[i])\n",
    "        else:\n",
    "            nulos +=1\n",
    "    if(nulos == len(vals)):\n",
    "        return None\n",
    "    else :\n",
    "        return media/validos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd_aemet[\"pres\"] = [media([pmax,pmin])for pmax,pmin in zip(pd_aemet[\"presMax\"].values, pd_aemet[\"presMin\"].values)]\n",
    "pd_aemet[\"temp\"] = [media([pmax,pmin])for pmax,pmin in zip(pd_aemet[\"tmax\"].values, pd_aemet[\"tmin\"].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd_aemet.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.2.8]- Rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd_aemet = pd_aemet[[\"indicativo\",\"fecha\",\"dir\",\"prec\",\"velmedia\",\"pres\",\"temp\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_aemet =pd_aemet.rename(columns={\"indicativo\":\"ESTACION\",\n",
    "                                   \"velmedia\":\"81\",                         \n",
    "                                   \"dir\":\"82\",\n",
    "                                   \"temp\":\"83\",\n",
    "                                   \"pres\":\"87\",\n",
    "                                   \"prec\":\"89\",\n",
    "                             })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.2.9] - Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = [\"ESTACION\",\"ANO\",\"MES\",\"DIA\",\"FECHA\"]\n",
    "for elem in magnitudes:\n",
    "    columnas.append(elem) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd_aemet = pd_aemet[columnas]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.2.10] - \"None\" a Nulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd_aemet = pd_aemet.replace(('None',None),np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.2.11] - Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_aemet[\"ANO\"] =pd_aemet[\"ANO\"].astype(int)\n",
    "pd_aemet[\"MES\"] =pd_aemet[\"MES\"].astype(int)\n",
    "pd_aemet[\"DIA\"] =pd_aemet[\"DIA\"].astype(int)\n",
    "pd_aemet[\"FECHA\"] =pd_aemet[\"FECHA\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [1.3]  ----------------------- AYUNTAMIENTO -----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Todas las estaciones miden todas las variables:\n",
    " \n",
    "        SI -81 - VELOCIDAD VIENTO   \n",
    "        SI -82 - DIR. DE VIENTO       \n",
    "        SI -83 - TEMPERATURA\n",
    "        NO -86 - HUMEDAD RELATIVA\n",
    "        SI -87 - PRESION BARIOMETRICA\n",
    "        NO -88 - RADIACION SOLAR\n",
    "        SI -89 - PRECIPITACIÓN\n",
    "       \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.3.0] - Obtenemos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "anos = [2019,2020]\n",
    "urls = [\"https://datos.madrid.es/egob/catalogo/300351-0-meteorologicos-diarios.csv\",\n",
    "        \"https://datos.madrid.es/egob/catalogo/300351-3-meteorologicos-diarios.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pd_read_to_df(url):\n",
    "    pdf = pd.read_csv(url,sep=';')\n",
    "    df = spark.createDataFrame(pdf)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = [pd_read_to_df(urls[i])for i in range(len(anos))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ayunt_19 = lista[0]\n",
    "for i in range(1,len(lista)):\n",
    "    df_ayunt_19=df_ayunt_19.union(lista[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.3.1] - Estaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DF info de todas las estaciones Clima utilizadas del AYUNTAMIENT0\n",
    "df_estaciones_ayunt_19 = df_estaciones.filter(df_estaciones[\"MIDE_CLIMA\"]>0).filter(df_estaciones[\"U_TODAS\"])\n",
    "#Lista con codigos_cortos de las estaciones anteriores.\n",
    "cod_estaciones_ayunt_19 = [elem[0] for elem in df_estaciones_ayunt_19.select(\"CODIGO_CORTO\").collect()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.3.2] -  Filtrar  -> ESTACIONES UTILIZADAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_ayunt_19 = df_ayunt_19.filter(df_ayunt_19[\"ESTACION\"].isin(cod_estaciones_ayunt_19))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.3.3] - Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ayunt_19 = df_ayunt_19.select('ESTACION','MAGNITUD','ANO', 'MES', 'D01', 'V01', 'D02', 'V02', 'D03', 'V03', 'D04', 'V04', 'D05', 'V05', 'D06', 'V06', 'D07', 'V07', 'D08', 'V08', 'D09', 'V09', 'D10', 'V10', 'D11', 'V11', 'D12', 'V12', 'D13', 'V13', 'D14', 'V14', 'D15', 'V15', 'D16', 'V16', 'D17', 'V17', 'D18','V18', 'D19', 'V19', 'D20', 'V20', 'D21', 'V21', 'D22', 'V22', 'D23', 'V23', 'D24', 'V24', 'D25', 'V25', 'D26', 'V26', 'D27', 'V27', 'D28', 'V28', 'D29', 'V29', 'D30', 'V30', 'D31', 'V31')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.3.4] - Formato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dar_formato(df):\n",
    "    data_schema = [StructField('ESTACION',IntegerType(), False), \n",
    "              StructField('MAGNITUD',IntegerType(), False),\n",
    "              StructField('ANO',IntegerType(), False),\n",
    "              StructField('MES',IntegerType(), False),\n",
    "              StructField('VALOR',FloatType(), True),\n",
    "              StructField('VALIDO',IntegerType(), False),\n",
    "              StructField('DIA',IntegerType(), False)]\n",
    "    struct = StructType(fields = data_schema)\n",
    "\n",
    "    df_v1 = spark.createDataFrame(spark.sparkContext.emptyRDD(),struct)\n",
    "    \n",
    "\n",
    "    for i in range(1,32): #Días  \n",
    "        valor = 'D%02d' % i\n",
    "        valido = 'V%02d' % i\n",
    "        df_v1 = df_v1.union(df.select(\"ESTACION\",\"MAGNITUD\",\"ANO\",\"MES\",valor,valido).withColumn('DIA', F.lit(i)))\n",
    "\n",
    "    df = df_v1\n",
    "\n",
    "    df = df.withColumn(\"FECHA\",df[\"ANO\"]*10000 + df[\"MES\"]*100 + df[\"DIA\"])\n",
    "\n",
    "    cols = df.columns\n",
    "    cols = cols[:4] + cols[-2:] + cols[-4:-2]\n",
    "    df= df[cols]\n",
    "\n",
    "    df = df.withColumn(\"VALOR VALIDADO\",F.when(F.col(\"VALIDO\")== 'N',None).otherwise(F.col(\"VALOR\")) )\n",
    "    df = df.select(\"ESTACION\",\"MAGNITUD\",\"ANO\",\"MES\",\"DIA\",\"FECHA\",df[\"VALOR VALIDADO\"].alias(\"VALOR\"))\n",
    "\n",
    "    df = df.groupBy('ESTACION','ANO', 'MES', 'DIA',\"FECHA\").pivot(\"MAGNITUD\").sum(\"VALOR\").orderBy(\"FECHA\")\n",
    "\n",
    "    #Esto se puede hacer en el paso 6\n",
    "    df_31 = df.filter(df[\"MES\"].isin([1,3,5,7,8,10,12]))\n",
    "    df_30 = df.filter((df[\"MES\"].isin([4,6,9,11])) & (df[\"DIA\"] <31))\n",
    "    df_feb = df.filter((df[\"MES\"] == 2) & (df[\"DIA\"] <30)) #Para no excluir los bisiestos\n",
    "    df = df_31.union(df_30).union(df_feb)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_ayunt_19 = dar_formato(df_ayunt_19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.3.5] - Select -> [ESTACION,ANO,MES,DIA,FECHA,+MAGNITUDES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd_ayunt_19 = df_ayunt_19.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_ayunt = pd_ayunt_19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = pd_ayunt.columns.to_list()[:5]\n",
    "for elem in magnitudes:\n",
    "    columnas.append(elem) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_ayunt = pd_ayunt[columnas]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [2] -  Union AYUNT + AEMET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pd_aemet.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pd_ayunt.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_final = pd.concat([pd_ayunt,pd_aemet])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [3] - Formato"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3.1] - 89-PRECIPITACION == \"IP\" == Inapreciable -> 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_final[\"89\"] = [elem if elem != \"Ip\" else 0 for elem in pd_final[\"89\"].values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3.2] - Rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_final = pd_final.rename(columns={\"ESTACION\":\"CODIGO_CORTO\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3.3] - Tipos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for magnitud in magnitudes:\n",
    "    pd_final[magnitud]  =  [reg.sub(',','.',str(x)) for x in pd_final[magnitud]]\n",
    "    # String to float\n",
    "    pd_final[magnitud] = pd_final[magnitud].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3.3] - Nulos -> Media diaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#pd_final[(pd_final[\"FECHA\"]==20190101)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dias = set(pd_final[\"FECHA\"].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd_means = pd_final.groupby(by = [\"ANO\",\"MES\",\"DIA\"]).agg('mean')\n",
    "for magnitud in magnitudes:\n",
    "    for dia in dias:\n",
    "        media_magnitud_dia = pd_means[pd_means[\"FECHA\"]== int(dia)][magnitud].values[0]       \n",
    "        pd_final.loc[pd_final[\"FECHA\"]==int(dia),magnitud] = [elem if pd.notnull(elem) else media_magnitud_dia\n",
    "                                                              for elem in pd_final[pd_final[\"FECHA\"]== int(dia)][magnitud].values]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd_final[(pd_final[\"FECHA\"]>20010101)&(pd_final[\"FECHA\"]<20010120)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [4] -Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pd_final.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BackUp\n",
    "hoy = datetime.date.today().strftime(\"%Y-%m-%d\")\n",
    "pd_final.to_csv(\"/home/rulicering/Datos_Proyecto_Ozono/Procesado/Clima/BackUp/Clima_diario_2001-202004-\"+ hoy + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd_final.to_csv(\"/home/rulicering/Datos_Proyecto_Ozono/Procesado/Clima/Clima_diario_2001-202004.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " try:\n",
    "    api_response = api_observacion.datos_de_observacin__tiempo_actual_1(3195)\n",
    "    pprint(api_response)\n",
    "except ApiException as e:\n",
    "    print(\"Exception: %s\\n\" % e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
