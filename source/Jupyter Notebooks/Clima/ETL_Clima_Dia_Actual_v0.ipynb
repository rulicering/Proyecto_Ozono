{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [o3] - Proyecto Ozono - ETL_Clima_Dia_Actual  - v0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [INFO]\n",
    "    \n",
    "       SOLO AEMET PROPORCIONA DATOS ACTUALES DE CLIMA \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    0. Inicialización\n",
    "    1. Datos\n",
    "        1.0 Carga fichero Estaciones\n",
    "        1.1 Lista magnitudes \n",
    "        1.2 ----------------------- AEMET -----------------------\n",
    "            1.2.0 Codegen + API\n",
    "            1.2.1 [FUNCION] -  Formateo datos\n",
    "            1.2.2 [FUNCIONES] - Request datos\n",
    "            1.2.3 _______ 2014-2018 _______\n",
    "                1.2.3.0 Estaciones \n",
    "                1.2.3.1 Fechas\n",
    "                1.2.3.2 Obtenemos los datos\n",
    "            1.2.4 _______ 2019-NOW ________\n",
    "                1.2.4.0 Estaciones\n",
    "                1.2.4.1 Fechas [20190101 - 2020 Ultimo mes cerrado]\n",
    "                1.2.4.2 Obtenemos los datos\n",
    "            1.2.5 Union\n",
    "            1.2.6 Columnas -> ANO,MES,DIA,FECHA\n",
    "            1.2.7 Columnas -> avg(Temp), avg(Pres)\n",
    "            1.2.8 Rename\n",
    "            1.2.9 Select\n",
    "            1.2.10 \"None\" a NULO\n",
    "            1.2.11 Types\n",
    "        1.3 ----------------------- AYUNTAMIENTO -----------------------\n",
    "            1.3.0 Obtenemos los datos\n",
    "            1.3.1 Estaciones\n",
    "            1.3.2 Filtar -> ESTACIONES UTILIZADAS\n",
    "            1.3.3 Select\n",
    "            1.3.4 Formato\n",
    "            1.3.5 Select -> [ESTACION,ANO,MES,DIA,FECHA,+MAGNITUDES]\n",
    "    2. Union AYUNT + AEMET\n",
    "    3. Formato\n",
    "        3.1 89-PRECIPITACION == \"IP\" == Inapreciable -> 0\n",
    "        3.2 Rename\n",
    "    4. Export\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [0] - Inicialización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import swagger_client\n",
    "from swagger_client.rest import ApiException\n",
    "from pprint import pprint\n",
    "import datetime\n",
    "import findspark\n",
    "findspark.init('/home/rulicering/BigData/spark-2.4.5-bin-hadoop2.7')\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import requests\n",
    "import numpy as np\n",
    "import re as reg\n",
    "from pyspark.sql.types import StructField,StringType,IntegerType,StructType,FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('clima_hoy').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [1] -  Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1.0] - Carga fichero Estaciones HOY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_estaciones = spark.read.csv(\"/home/rulicering/Datos_Proyecto_Ozono/Procesado/Estaciones/Estaciones-hoy.csv\",inferSchema= True, header= True)\n",
    "#Fuerzo que se ejecute para que luego al filtrar no tenga que volver a leer el csv\n",
    "df_estaciones = spark.createDataFrame(df_estaciones.toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1.1] - Lista magnitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = reg.compile(\"E_AEMET_HOY\")\n",
    "c_aemet_hoy = [elem for elem in list(filter(regex.search,df_estaciones.columns))]\n",
    "c_magnitudes_aemet_hoy = [elem[-2:] for elem in list(filter(regex.search,df_estaciones.columns))]\n",
    "#c_magnitudes_aemet_hoy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1.2]  ----------------------- AEMET -----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    81 - VELOCIDAD VIENTO\n",
    "    82 - DIR. DE VIENTO\n",
    "    83 - TEMPERATURA \n",
    "    87 - PRESION BARIOMETRICA\n",
    "    89 - PRECIPITACIÓN    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.2.0] - Codegen + API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = swagger_client.Configuration()\n",
    "configuration.api_key['api_key'] = 'eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJwcm95ZWN0by5vem9uby5jb250YWN0QGdtYWlsLmNvbSIsImp0aSI6ImNlZDZiZWQ2LTUyN2EtNGQ2Yi1iOGMyLWU1YmRlNzk3YzYzZSIsImlzcyI6IkFFTUVUIiwiaWF0IjoxNTg2NzE3MTE2LCJ1c2VySWQiOiJjZWQ2YmVkNi01MjdhLTRkNmItYjhjMi1lNWJkZTc5N2M2M2UiLCJyb2xlIjoiIn0.U3b4ELAg-9eJcwgpzr4QgkF-Yj6jb9gw0DOa8sqAwHo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#api_instance = swagger_client.AvisosCapApi(swagger_client.ApiClient(configuration))\n",
    "api_observacion = swagger_client.ObservacionConvencionalApi(swagger_client.ApiClient(configuration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.2.1] - [FUNCION] -  Formateo datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_sparkdf(data):\n",
    "    #Encoding \"ISO-8859\"\n",
    "    data_v = data.decode(encoding ='ISO-8859-15')\n",
    "    data_v0 = data_v\n",
    "\n",
    "    # Clean the data\n",
    "    # Step 0 \n",
    "    for i in range(20):\n",
    "        if(data_v0[i]=='{'):\n",
    "            data_v0 = data_v0[i:]\n",
    "    for i in range(20):\n",
    "        if(data_v0[-i]=='}'):\n",
    "            data_v0 = data_v0[:-i+1]\n",
    "            \n",
    "    # Step 1     \n",
    "    data_v1 = data_v0\n",
    "    data_v1 = data_v1.replace(\"\\n\", \"\")\n",
    "    \n",
    "    # Step 2\n",
    "    data_v2 = data_v1.replace(\"},\",\"}};\")\n",
    "    \n",
    "    # Step 3\n",
    "    patron =['\\s\\s','\\s\"','\"\\s','\\s{']\n",
    "    replace = [' ','\"','\"','{']\n",
    "    \n",
    "    data_v3 = data_v2\n",
    "    for i in range(len(patron)):\n",
    "        data_v3 = reg.sub(patron[i],replace[i],data_v3)\n",
    "\n",
    "    # Step 4\n",
    "    data_v4 = data_v3.replace(\",\",\";\")\n",
    " \n",
    "    #Step 5 \n",
    "    data_v5 = data_v4.replace(\"\\\"\", \"\")\n",
    "    \n",
    "    # Step 6\n",
    "    data_cleaned = data_v5.split(\"};\")\n",
    "\n",
    "\n",
    "    # String to List of dictionaries\n",
    "    diccionarios = []\n",
    "    for fila in data_cleaned:\n",
    "        #print(fila)\n",
    "        keys = []\n",
    "        values = []\n",
    "        for pareja in fila[1:-1].split(';'):\n",
    "            #print(\"Pareja= \",pareja)\n",
    "            elems =pareja.split(':')\n",
    "            #print(\"Elementos= \",elems)\n",
    "            keys.append(elems[0])\n",
    "            values.append(elems[1])\n",
    "        diccionarios.append(dict(zip(keys,values)))\n",
    "        \n",
    "    # Schema for the new DF\n",
    "    data_schema = [StructField('idema',StringType(), False), #Tercer argumento = nullable\n",
    "                   StructField('lon', StringType(), True),\n",
    "                   StructField('fint', StringType(), True),\n",
    "                   StructField('prec', StringType(), True),\n",
    "                   StructField('alt', StringType(), True),\n",
    "                   StructField('vmax', StringType(), True),\n",
    "                   StructField('vv', StringType(), True),\n",
    "                   StructField('dv',StringType(), True), \n",
    "                   StructField('lat', StringType(), True),\n",
    "                   StructField('dmax', StringType(), True),\n",
    "                   StructField('ubi', StringType(), True),\n",
    "                   StructField('pres', StringType(), True),\n",
    "                   StructField('hr',StringType(), True), \n",
    "                   StructField('ts', StringType(), True),\n",
    "                   StructField('pres_nmar', StringType(), True),\n",
    "                   StructField('tamin', StringType(), True),\n",
    "                   StructField('ta', StringType(), True),\n",
    "                   StructField('tamax', StringType(), True),\n",
    "                   StructField('tpr', StringType(), True),\n",
    "                   StructField('vis', StringType(), True),\n",
    "                   StructField('stddv', StringType(), True),\n",
    "                   StructField('inso', StringType(), True),\n",
    "                   StructField('rviento', StringType(), True),\n",
    "                  ]\n",
    "    # Create and return the new DF\n",
    "    return spark.createDataFrame(diccionarios,schema = StructType(data_schema))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.2.2]  [FUNCIONES] - Request datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def req_hoy_to_df(codigo):\n",
    "    print(\"CODIGO: \", codigo)\n",
    "    try:\n",
    "        api_response = api_observacion.datos_de_observacin__tiempo_actual_1(codigo)\n",
    "        pprint(api_response)\n",
    "    except ApiException as e:\n",
    "        pprint(api_response)\n",
    "        print(\"Exception: %s\\n\" % e)\n",
    "    r = requests.get(api_response.datos)\n",
    "    data = r.content\n",
    "    df_aemet = data_to_sparkdf(data)\n",
    "    print(\"OK\")\n",
    "    \n",
    "    return df_aemet.select('idema','fint','prec','pres','tamax','tamin','dv','vv')\n",
    "    \n",
    "    # Las estaciones del ayunt no tienen datos de insolacion (sol)\n",
    "    #return df_aemet.select('fecha','indicativo','dir','prec','presMax','presMin','sol','tmax','tmin','velmedia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datos_aemet_hoy(codigos_estaciones):\n",
    "    lista_df =[]\n",
    "    for codigo in codigos_estaciones:\n",
    "        lista_df.append(req_hoy_to_df(codigo))\n",
    "    #Unimos\n",
    "    df = lista_df[0]\n",
    "    for i in range(1,len(lista_df)):\n",
    "        df = df.union(lista_df[i])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.2.3]  _______ HOY _______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [1.2.3.0] - Estaciones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_estaciones_aemet_hoy = df_estaciones.filter(df_estaciones[\"U_AEMET_HOY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_estaciones_aemet_hoy = [elem[0] for elem in df_estaciones_aemet_hoy.select(\"CODIGO_CORTO\").collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3129', '3194U', '3195']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cod_estaciones_aemet_hoy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [1.2.3.2] -  Obtenemos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CODIGO:  3129\n",
      "{'datos': 'https://opendata.aemet.es/opendata/sh/36db8406',\n",
      " 'descripcion': 'exito',\n",
      " 'estado': 200,\n",
      " 'metadatos': 'https://opendata.aemet.es/opendata/sh/55c2971b'}\n",
      "OK\n",
      "CODIGO:  3194U\n",
      "{'datos': 'https://opendata.aemet.es/opendata/sh/305227b6',\n",
      " 'descripcion': 'exito',\n",
      " 'estado': 200,\n",
      " 'metadatos': 'https://opendata.aemet.es/opendata/sh/55c2971b'}\n",
      "OK\n",
      "CODIGO:  3195\n",
      "{'datos': 'https://opendata.aemet.es/opendata/sh/d592c85c',\n",
      " 'descripcion': 'exito',\n",
      " 'estado': 200,\n",
      " 'metadatos': 'https://opendata.aemet.es/opendata/sh/55c2971b'}\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "df_aemet_hoy = datos_aemet_hoy(cod_estaciones_aemet_hoy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aemet = df_aemet_hoy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.2.6] -Columnas -> ANO,MES,DIA,FECHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aemet = df_aemet.withColumn(\"ANO\",df_aemet[\"fint\"][0:4])\n",
    "df_aemet = df_aemet.withColumn(\"MES\",df_aemet[\"fint\"][6:2])\n",
    "df_aemet = df_aemet.withColumn(\"DIA\",df_aemet[\"fint\"][9:2])\n",
    "df_aemet = df_aemet.withColumn(\"HORA\",df_aemet[\"fint\"][12:2])\n",
    "df_aemet = df_aemet.withColumn(\"FECHA\",F.concat(df_aemet[\"fint\"][0:4],df_aemet[\"fint\"][6:2],df_aemet[\"fint\"][9:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.2.7] - Columna -> avg(Temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_aemet = df_aemet.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Cambias comas por puntos\n",
    "pd_aemet[\"tamax\"]  =  [reg.sub(',','.',str(x)) for x in pd_aemet[\"tamax\"]]\n",
    "pd_aemet[\"tamin\"]  =  [reg.sub(',','.',str(x)) for x in pd_aemet[\"tamin\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def media(vals):\n",
    "    validos = 0\n",
    "    nulos = 0\n",
    "    media = 0\n",
    "    for i in range(len(vals)):\n",
    "        if(vals[i] != 'None')or(vals[i] is None):\n",
    "            validos += 1\n",
    "            media += float(vals[i])\n",
    "        else:\n",
    "            nulos +=1\n",
    "    if(nulos == len(vals)):\n",
    "        return None\n",
    "    else :\n",
    "        return media/validos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd_aemet[\"temp\"] = [media([pmax,pmin])for pmax,pmin in zip(pd_aemet[\"tamax\"].values, pd_aemet[\"tamin\"].values)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.2.8]- Rename & Colocar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_aemet =pd_aemet.rename(columns={\"idema\":\"ESTACION\",\n",
    "                                   \"vv\":\"81\",                         \n",
    "                                   \"dv\":\"82\",\n",
    "                                   \"temp\":\"83\",\n",
    "                                   \"pres\":\"87\",\n",
    "                                   \"prec\":\"89\",\n",
    "                             })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.2.9] - FIltrar datos de hoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_aemet = pd_aemet[pd_aemet[\"DIA\"]==str(datetime.date.today().day)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.2.10] - Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = [\"ESTACION\",\"ANO\",\"MES\",\"DIA\",\"HORA\",\"FECHA\"]\n",
    "for elem in c_magnitudes_aemet_hoy:\n",
    "    columnas.append(elem) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd_aemet = pd_aemet[columnas]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.2.11] - Tipos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for elem in c_magnitudes_aemet_hoy:\n",
    "    pd_aemet[elem]= pd_aemet[elem].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.2.12] - Valores Diarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  [1.2.12.0] - AVERAGE DIA - (Presion,Temperatura,Velocidad del viento y Direccion del viento) + SUMA (Precipitaciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aemet = spark.createDataFrame(pd_aemet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aemet = df_aemet.groupBy([\"ESTACION\",\"ANO\",\"MES\",\"DIA\",\"FECHA\"]).agg({'81':'mean',\n",
    "                                                                         '82':'mean',\n",
    "                                                                         '83':'mean',\n",
    "                                                                         '87':'mean',\n",
    "                                                                         '89':'sum',})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.2.13] - Rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regex = reg.compile(\"avg\\(|sum\\(\")\n",
    "columnas = list(filter(regex.search,df_aemet.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "for columna in columnas:\n",
    "    df_aemet = df_aemet.withColumnRenamed(columna,columna[4:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.2.10] - \"None\" a Nulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd_aemet = df_aemet.toPandas()\n",
    "pd_aemet = pd_aemet.replace(('None',None),np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.2.11] - Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_aemet[\"ANO\"] =pd_aemet[\"ANO\"].astype(int)\n",
    "pd_aemet[\"MES\"] =pd_aemet[\"MES\"].astype(int)\n",
    "pd_aemet[\"DIA\"] =pd_aemet[\"DIA\"].astype(int)\n",
    "pd_aemet[\"FECHA\"] =pd_aemet[\"FECHA\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_final = pd_aemet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [3] - Formato"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3.1] - Rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd_final = pd_final.rename(columns={\"ESTACION\":\"CODIGO_CORTO\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [4] -Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd_final.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Versiones\n",
    "hoy = datetime.date.today().strftime(\"%Y-%m-%d\")\n",
    "pd_final.to_csv(\"/home/rulicering/Datos_Proyecto_Ozono/Procesado/Clima/BackUp/Clima_dia-\"+ hoy + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_final.to_csv(\"/home/rulicering/Datos_Proyecto_Ozono/Procesado/Clima/Clima_dia-hoy.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
