{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [o3] - Proyecto Ozono - ETL_Clima_Prediccion_[STRC]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [0] - Inicialización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import swagger_client\n",
    "from swagger_client.rest import ApiException\n",
    "from pprint import pprint\n",
    "import datetime\n",
    "import findspark\n",
    "findspark.init('/home/rulicering/BigData/spark-2.4.5-bin-hadoop2.7')\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import re as reg\n",
    "import json\n",
    "from pyspark.sql.types import StructField,StringType,IntegerType,StructType,FloatType\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClimaPrediccion():\n",
    "    \"\"\"\n",
    "    \n",
    "        FUNCIONES AUXILIARES<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    def convertir_a_diccionario(self,raw,inicio,tipo):\n",
    "        #Variables locales\n",
    "        i = inicio\n",
    "        iniciob = -1\n",
    "        #Dicionarios del tipo {}\n",
    "        diccionario = {}\n",
    "        #Diccionarios elementos de lista\n",
    "        lista = []\n",
    "        #Auxiliares\n",
    "        final = len(raw)\n",
    "        a_is_fixed = False \n",
    "\n",
    "        while i < final:\n",
    "            c = raw[i] #Caracter a leer\n",
    "            if(i > 0):c_ant = raw[i-1] # Caracter anterior\n",
    "\n",
    "            if((c == \":\") & ~(a_is_fixed)):\n",
    "                a_is_fixed = True\n",
    "                a = raw[inicio:i]\n",
    "                iniciob = i+1\n",
    "                b = ''\n",
    "\n",
    "            if(c == \";\" or c == \",\" ):\n",
    "                #Si estamos en una lista apilamos el diccionario recien leido\n",
    "                if(tipo == 2): lista.append(diccionario)\n",
    "                # Si no, 3 opciones: Lo anterior sea una lista,un diccionario o un valor literal.\n",
    "                else:\n",
    "                    a_is_fixed = False\n",
    "                    if(c_ant != \"]\")&(c_ant != \"}\"): #Para el valor literal, simplemente lo leemos\n",
    "                        b = raw[iniciob:i]\n",
    "                    diccionario[a] =  b #Para lista y diccionario cogemos b que ya guarda ese objeto\n",
    "                    inicio = i+1 #Siempre movemos el puntero inicio para que pueda leer otra key\n",
    "\n",
    "            if(c ==\"{\"):\n",
    "                b,i = self.convertir_a_diccionario(raw,i+1,1)\n",
    "\n",
    "                if(tipo != 2): #Si no estamos en una lista, añadimos el nuevo diccionario\n",
    "                    diccionario[a]=b\n",
    "                else: #Si estamos en una lista, este es un elemento de ella.\n",
    "                    diccionario  = b\n",
    "                inicio = i\n",
    "                a_is_fixed = False\n",
    "\n",
    "            if(c ==\"}\"):\n",
    "                if(c_ant != \"]\")&(c_ant != \"}\"): #Si era una lista el elemento no se cogen los literales\n",
    "                    b = raw[iniciob:i]\n",
    "                diccionario[a] = b\n",
    "                return diccionario, i\n",
    "\n",
    "            if(c == '['):\n",
    "                b,i = self.convertir_a_diccionario(raw,i+1,2)\n",
    "                inicio = i\n",
    "                a_is_fixed = False\n",
    "\n",
    "            if(c == ']'):\n",
    "                lista.append(diccionario)\n",
    "                return lista, i\n",
    "\n",
    "            i+=1\n",
    "        return diccionario\n",
    "        \n",
    "    def dic_to_df(self,dic):\n",
    "\n",
    "        mañana = (datetime.date.today()+datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "        #Sacamos los datos de hoy\n",
    "        i_dia = -1\n",
    "        for i in range(len(dic[\"prediccion\"][\"dia\"])):\n",
    "            fecha = dic[\"prediccion\"][\"dia\"][i][\"fecha\"][:10]\n",
    "            if(fecha == mañana):\n",
    "                i_dia = i\n",
    "                break\n",
    "        datos = dic[\"prediccion\"][\"dia\"][i_dia]\n",
    "\n",
    "        #Viento & Direccion\n",
    "        #Periodos de 6 horas\n",
    "        # Hacemos la media para la velocidad y cogemos la direccion del periodo de mayor velocidad\n",
    "        count = 0\n",
    "        agg = 0\n",
    "        direccion = ''\n",
    "        max_velocidad = -1\n",
    "        for elem in datos[\"viento\"]:\n",
    "            hora_ini, hora_fin = elem[\"periodo\"].split(\"-\")\n",
    "            velocidad = int(elem[\"velocidad\"])\n",
    "            if(int(hora_fin)-int(hora_ini)) <=6:\n",
    "                count +=1\n",
    "                agg+= velocidad\n",
    "                if(velocidad > max_velocidad):\n",
    "                    max_velocidad = velocidad\n",
    "                    direccion = elem[\"direccion\"]\n",
    "        viento = agg/count\n",
    "\n",
    "        #Temperatura\n",
    "        #Periodos de 6 horas, hacemos la media\n",
    "        count = 0\n",
    "        agg = 0\n",
    "        for elem in datos[\"temperatura\"][\"dato\"]:\n",
    "            count +=1\n",
    "            agg+= int(elem[\"value\"])\n",
    "        temp = agg/count\n",
    "\n",
    "        #Prob-Precipitacion\n",
    "        # Periodos de 6 horas - Cogemos el valor máximo\n",
    "        count = 0\n",
    "        agg = 0\n",
    "        max_probabilidad = 0.0\n",
    "        for elem in datos[\"probPrecipitacion\"]:\n",
    "            hora_ini, hora_fin = elem[\"periodo\"].split(\"-\")\n",
    "            probabilidad = int(elem[\"value\"])\n",
    "            if(int(hora_fin)-int(hora_ini)) <=6:\n",
    "                if(probabilidad > max_probabilidad):\n",
    "                    max_probabilidad= probabilidad\n",
    "\n",
    "        diccionarios = []\n",
    "        diccionarios.append({\"FECHA\" : mañana,\"VIENTO\" : viento,\"DIRECCION\" : direccion,\n",
    "                            \"TEMPERATURA\" : temp , \"PRESION\": -1.0,\n",
    "                            \"PROBPRECIPITACION\" : float(max_probabilidad)})\n",
    "\n",
    "        # Schema for the new DF\n",
    "        data_schema = [StructField('FECHA',StringType(), True), #Tercer argumento = nullable\n",
    "                       StructField('VIENTO', FloatType(), True),\n",
    "                       StructField('DIRECCION', StringType(), True),\n",
    "                       StructField('TEMPERATURA', FloatType(), True),\n",
    "                       StructField('PRESION', FloatType(), True),\n",
    "                       StructField('PROBPRECIPITACION', FloatType(), True)\n",
    "                      ]\n",
    "\n",
    "        return self.spark.createDataFrame(diccionarios,schema = StructType(data_schema)) \n",
    "    \n",
    "    def data_to_sparkdf(self,data):\n",
    "        #Encoding \"ISO-8859\"\n",
    "        data_v = data.decode(encoding ='ISO-8859-15')\n",
    "        data_v0 = data_v\n",
    "\n",
    "        # Clean the data\n",
    "        # Step 0 - Acotamos final e inicio\n",
    "        for i in range(50):\n",
    "            if(data_v0[i]=='{'):\n",
    "                data_v0 = data_v0[i+1:]\n",
    "                break\n",
    "        for i in range(50):\n",
    "            if(data_v0[-i]=='}'):\n",
    "                data_v0 = data_v0[:-i]   \n",
    "                break\n",
    "\n",
    "        # Step 1 - Saltos de linea    \n",
    "        data_v1 = data_v0\n",
    "        data_v1 = data_v1.replace(\"\\n\", \"\")\n",
    "\n",
    "        # Step 2 - Evitar problemas -> };\n",
    "        data_v2 = data_v1.replace(\"},\",\"};\")\n",
    "\n",
    "        # Step 3 - Espacios en blanco\n",
    "        patron =['\\s','\\s\"','\"\\s','\\s{',':/']\n",
    "        replace = ['','\"','\"','{','/']\n",
    "\n",
    "        data_v3 = data_v2\n",
    "        for i in range(len(patron)):\n",
    "            data_v3 = reg.sub(patron[i],replace[i],data_v3)\n",
    "\n",
    "        # Step 4 - Separadores -> ;\n",
    "        data_v4 = data_v3.replace(\"\\\",\\\"\",\"\\\";\\\"\")\n",
    "\n",
    "        #Step 5 - Comillas\n",
    "        data_clean = data_v4.replace(\"\\\"\", \"\")\n",
    "\n",
    "        diccionario = self.convertir_a_diccionario(data_clean,0,0)\n",
    "\n",
    "        #Sacamos los datos que queremos\n",
    "        return self.dic_to_df(diccionario)\n",
    "    \n",
    "    def req_to_df(self,codigo):\n",
    "        print(\"PREDICCIONES ZONA: \", codigo)\n",
    "        try:\n",
    "            api_response = self.api_predicciones.prediccin_por_municipios_diaria__tiempo_actual_(codigo)\n",
    "            pprint(api_response)\n",
    "        except ApiException as e:\n",
    "            print(\"Exception: %s\\n\" % e)\n",
    "        r = requests.get(api_response.datos)\n",
    "        data = r.content\n",
    "        df_aemet = self.data_to_sparkdf(data)\n",
    "        print (\"OK\")\n",
    "        return df_aemet\n",
    "    \n",
    "    def datos_predicciones_aemet(self,codigos_zonas):\n",
    "        lista_df =[]\n",
    "        for codigo in codigos_zonas:\n",
    "            lista_df.append(self.req_to_df(codigo))\n",
    "        #Unimos\n",
    "        df = lista_df[0]\n",
    "        for i in range(1,len(lista_df)):\n",
    "            df = df.union(lista_df[i])\n",
    "        return df  \n",
    "    \n",
    "    @staticmethod\n",
    "    def dir_to_grad(direccion):\n",
    "        if(direccion == 'E'): return 0\n",
    "        if(direccion == 'NE'): return 45\n",
    "        if(direccion == 'N'): return 90\n",
    "        if(direccion == 'NO'): return 135\n",
    "        if(direccion == 'O'): return 180\n",
    "        if(direccion == 'SO'): return 225\n",
    "        if(direccion == 'S'): return 270\n",
    "        if(direccion == 'SE'): return 315\n",
    "        if(direccion == 'C'): return None  \n",
    "        \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "        FUNCIONES PRINCIPALES <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "    \n",
    "    \n",
    "    \"\"\"   \n",
    "    def __init__(self):\n",
    "        self.spark = SparkSession.builder.appName('clima_prediccion').getOrCreate()\n",
    "        self.spark.sparkContext.setLogLevel('ERROR')\n",
    "        \n",
    "        #API Aemet\n",
    "        f = open(\"/home/rulicering/Datos_Proyecto_Ozono/Credenciales/Credenciales.json\")\n",
    "        credenciales = json.load(f)\n",
    "        AEMET_API_KEY = credenciales[\"aemet\"][\"api_key\"]\n",
    "        configuration = swagger_client.Configuration()\n",
    "        configuration.api_key['api_key'] = AEMET_API_KEY\n",
    "        self.api_predicciones = swagger_client.PrediccionesEspecificasApi(swagger_client.ApiClient(configuration))\n",
    "    \n",
    "    def process(self):\n",
    "        self.prediccion()\n",
    "        self.carga()\n",
    "        \n",
    "    def prediccion(self):\n",
    "        #Código zona MADRID CIUDAD\n",
    "        codigos_zonas = [\"28079\"]\n",
    "        df_predicciones = self.datos_predicciones_aemet(codigos_zonas)\n",
    "        \n",
    "        df_predicciones = df_predicciones.withColumn(\"ANO\",df_predicciones[\"FECHA\"][0:4])\n",
    "        df_predicciones = df_predicciones.withColumn(\"MES\",df_predicciones[\"FECHA\"][6:2])\n",
    "        df_predicciones = df_predicciones.withColumn(\"DIA\",df_predicciones[\"FECHA\"][9:2])\n",
    "        df_predicciones = df_predicciones.withColumn(\"FECHA\",F.concat(df_predicciones[\"FECHA\"][0:4],df_predicciones[\"FECHA\"][6:2],df_predicciones[\"FECHA\"][9:2]))\n",
    "        \n",
    "        my_udf = F.udf(ClimaPrediccion.dir_to_grad,IntegerType())\n",
    "        df_predicciones = df_predicciones.withColumn(\"DIRECCION\",my_udf(df_predicciones[\"DIRECCION\"]))\n",
    "        \n",
    "        #Rename\n",
    "        pd_predicciones = df_predicciones.toPandas()\n",
    "        pd_predicciones =pd_predicciones.rename(columns={ \"VIENTO\":\"81\",                         \n",
    "                                                   \"DIRECCION\":\"82\",\n",
    "                                                   \"TEMPERATURA\":\"83\",     \n",
    "                                                   \"PRESION\":\"87\",\n",
    "                                                   \"PROBPRECIPITACION\":\"%89\",\n",
    "                                             })\n",
    "        #Tipos\n",
    "        pd_predicciones[\"ANO\"] =pd_predicciones[\"ANO\"].astype(int)\n",
    "        pd_predicciones[\"MES\"] =pd_predicciones[\"MES\"].astype(int)\n",
    "        pd_predicciones[\"DIA\"] =pd_predicciones[\"DIA\"].astype(int)\n",
    "        pd_predicciones[\"FECHA\"] =pd_predicciones[\"FECHA\"].astype(int)\n",
    "        \n",
    "        #Columnas\n",
    "        cols = pd_predicciones.columns.tolist()\n",
    "        cols = cols[0:1]+ cols[-3:] + cols[1:-3]\n",
    "        self.pd_predicciones = pd_predicciones[cols]\n",
    "    \n",
    "    def carga(self):\n",
    "        pd_final = self.pd_predicciones\n",
    "        nuevo = (datetime.date.today() + datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "        anterior = datetime.date.today().strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        #BackUp\n",
    "        pd_final.to_csv(\"/home/rulicering/Datos_Proyecto_Ozono/Procesado/Clima/BackUp/Clima_Prediccion-\"+ nuevo + \".csv\")\n",
    "        pd_final.to_csv(\"/home/rulicering/Datos_Proyecto_Ozono/Procesado/Clima/Clima_Prediccion-\"+ nuevo + \".csv\")\n",
    "        print(\"[INFO] - Clima_Prediccion-\"+ nuevo +\".csv --- Created successfully\")\n",
    "        \n",
    "        #Borrar la de ayer\n",
    "        try:\n",
    "            os.remove(\"/home/rulicering/Datos_Proyecto_Ozono/Procesado/Clima/Clima_Prediccion-\"+ anterior + \".csv\")\n",
    "            print(\"[INFO] - Clima_Prediccion-\"+ anterior +\".csv --- Removed successfully\")\n",
    "        except:\n",
    "            print(\"[ERROR] - Clima_Prediccion-\"+ anterior +\".csv --- Could not been removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clima_prediccion = ClimaPrediccion()\n",
    "clima_prediccion.process()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
