{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [o3] - Proyecto Ozono - ETL_Clima  - v0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [.0] AEMET Y AYUNT -> DATOS A MES CERRADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "import swagger_client\n",
    "from swagger_client.rest import ApiException\n",
    "from pprint import pprint\n",
    "import datetime\n",
    "import findspark\n",
    "findspark.init('/home/rulicering/BigData/spark-2.4.5-bin-hadoop2.7')\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re as reg\n",
    "from pyspark.sql.types import StructField,StringType,IntegerType,StructType,FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('clima').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargamos Estaciones.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_estaciones = spark.read.csv(\"/home/rulicering/Datos_Proyecto_Ozono/Procesado/Estaciones/Estaciones.csv\",inferSchema= True, header= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AEMET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Codegen + API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = swagger_client.Configuration()\n",
    "configuration.api_key['api_key'] = 'eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJwcm95ZWN0by5vem9uby5jb250YWN0QGdtYWlsLmNvbSIsImp0aSI6ImNlZDZiZWQ2LTUyN2EtNGQ2Yi1iOGMyLWU1YmRlNzk3YzYzZSIsImlzcyI6IkFFTUVUIiwiaWF0IjoxNTg2NzE3MTE2LCJ1c2VySWQiOiJjZWQ2YmVkNi01MjdhLTRkNmItYjhjMi1lNWJkZTc5N2M2M2UiLCJyb2xlIjoiIn0.U3b4ELAg-9eJcwgpzr4QgkF-Yj6jb9gw0DOa8sqAwHo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#api_instance = swagger_client.AvisosCapApi(swagger_client.ApiClient(configuration))\n",
    "api_observacion = swagger_client.ObservacionConvencionalApi(swagger_client.ApiClient(configuration))\n",
    "master_api_instance = swagger_client.MaestroApi(swagger_client.ApiClient(configuration))\n",
    "api_valores = swagger_client.ValoresClimatologicosApi(swagger_client.ApiClient(configuration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formateo datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_sparkdf(data):\n",
    "    #Encoding \"ISO-8859\"\n",
    "    data_v = data.decode(encoding ='ISO-8859-15')\n",
    "    data_v0 = data_v\n",
    "    # Clean the data\n",
    "    # Step 0 \n",
    "    for i in range(20):\n",
    "        if(data_v0[i]=='{'):\n",
    "            data_v0 = data_v0[i:]\n",
    "    for i in range(20):\n",
    "        if(data_v0[-i]=='}'):\n",
    "            data_v0 = data_v0[:-i+1]\n",
    "    # Step 1     \n",
    "    data_v1 = data_v0\n",
    "    data_v1 = data_v1.replace(\"\\n\", \"\")\n",
    "    \n",
    "    # Step 2\n",
    "    data_v2 = data_v1.replace(\"},\",\"}},\")\n",
    "    \n",
    "    # Step 3\n",
    "    patron =['\\s\\s','\\s\"','\"\\s','\\s{']\n",
    "    replace = [' ','\"','\"','{']\n",
    "    \n",
    "    data_v3 = data_v2\n",
    "    for i in range(len(patron)):\n",
    "        data_v3 = reg.sub(patron[i],replace[i],data_v3)\n",
    "\n",
    "    # Step 4\n",
    "    data_v4 = data_v3.replace(\"\\\",\\\"\",\"\\\";\\\"\")\n",
    "    \n",
    "    # Step 5\n",
    "    data_cleaned = data_v4.split(\"},\")\n",
    "\n",
    "    # String to List of dictionaries\n",
    "    diccionarios = []\n",
    "    for fila in data_cleaned:\n",
    "        #print(fila)\n",
    "        keys = []\n",
    "        values = []\n",
    "        for pareja in fila[1:-1].split(';'):\n",
    "            #print(\"Pareja= \",pareja)\n",
    "            elems =pareja.split(':')\n",
    "            #print(\"Elementos= \",elems)\n",
    "            keys.append(elems[0][1:-1])\n",
    "            values.append(elems[1][1:-1])\n",
    "        diccionarios.append(dict(zip(keys,values)))\n",
    "\n",
    "    # Schema for the new DF\n",
    "    data_schema = [StructField('altitud',StringType(), True), #Tercer argumento = nullable\n",
    "                   StructField('dir', StringType(), True),\n",
    "                   StructField('fecha', StringType(), True),\n",
    "                   StructField('horaPresMax', StringType(), True),\n",
    "                   StructField('horaPresMin', StringType(), True),\n",
    "                   StructField('horaracha', StringType(), True),\n",
    "                   StructField('horatmax', StringType(), True),\n",
    "                   StructField('horatmin',StringType(), True), #Tercer argumento = nullable\n",
    "                   StructField('indicativo', StringType(), True),\n",
    "                   StructField('nombre', StringType(), True),\n",
    "                   StructField('prec', StringType(), True),\n",
    "                   StructField('presMax', StringType(), True),\n",
    "                   StructField('presMin',StringType(), True), #Tercer argumento = nullable\n",
    "                   StructField('provincia', StringType(), True),\n",
    "                   StructField('racha', StringType(), True),\n",
    "                   StructField('sol', StringType(), True),\n",
    "                   StructField('tmax', StringType(), True),\n",
    "                   StructField('tmin', StringType(), True),\n",
    "                   StructField('velmedia', StringType(), True)\n",
    "                  ]\n",
    "    # Create and return the new DF\n",
    "    return spark.createDataFrame(diccionarios,schema = StructType(data_schema))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def req_to_df(codigo,fecha_ini,fecha_fin):\n",
    "    print(\"CODIGO: \", codigo, \"FECHAS\", fecha_ini,fecha_fin)\n",
    "    try:\n",
    "        api_response = api_valores.climatologas_diarias_(fecha_ini, fecha_fin,codigo)\n",
    "        #pprint(api_response)\n",
    "    except ApiException as e:\n",
    "        print(\"Exception: %s\\n\" % e)\n",
    "    r = requests.get(api_response.datos)\n",
    "    data = r.content\n",
    "    df_aemet = data_to_sparkdf(data)\n",
    "    print(\"OK\")\n",
    "    return df_aemet.select('fecha','indicativo','dir','prec','presMax','presMin','sol','tmax','tmin','velmedia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datos_aemet(codigos_estaciones,fecha_ini,fecha_fin):\n",
    "    lista_pd =[]\n",
    "    for codigo in codigos_estaciones:\n",
    "        lista_pd.append(req_to_df(codigo,fecha_ini,fecha_fin))\n",
    "    #Unimos\n",
    "    df = lista_pd[0]\n",
    "    for i in range(1,len(lista_pd)):\n",
    "        df = df.union(lista_pd[i])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2014-2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estaciones AEMET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_estaciones_aemet_14 = df_estaciones.filter(df_estaciones[\"UTILIZADA_14\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_estaciones_aemet_14 = [elem[0] for elem in df_estaciones_aemet_14.select(\"CODIGO_CORTO\").collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3129', '3194U', '3195', '3200']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cod_estaciones_aemet_14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fechas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fechas inicio y fecha fin datos\n",
    "fecha_ini = datetime.date(2014,1,1)\n",
    "fecha_fin = datetime.date(2018,12,31)\n",
    "\n",
    "formato= \"%Y-%m-%dT%H:%M:%SUTC\"\n",
    "\n",
    "fecha_ini_str = fecha_ini.strftime(formato)\n",
    "fecha_fin_str = fecha_fin.strftime(formato)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtenemos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CODIGO:  3129 FECHAS 2019-01-01T00:00:00UTC 2020-03-31T00:00:00UTC\n",
      "OK\n",
      "CODIGO:  3194U FECHAS 2019-01-01T00:00:00UTC 2020-03-31T00:00:00UTC\n",
      "OK\n",
      "CODIGO:  3195 FECHAS 2019-01-01T00:00:00UTC 2020-03-31T00:00:00UTC\n",
      "OK\n",
      "CODIGO:  3200 FECHAS 2019-01-01T00:00:00UTC 2020-03-31T00:00:00UTC\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "df_aemet_14 = datos_aemet(cod_estaciones_aemet_14,fecha_ini_str,fecha_fin_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2019-NOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estaciones AEMET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_estaciones_aemet_19 = df_estaciones.filter(df_estaciones[\"MIDE_CLIMA_AEMET\"]>0).filter(df_estaciones[\"UTILIZADA_19\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_estaciones_aemet_19 = [elem[0] for elem in df_estaciones_aemet_19.select(\"CODIGO_CORTO\").collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3129', '3194U', '3195']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cod_estaciones_aemet_19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fechas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fechas inicio y fecha fin datos\n",
    "fecha_ini = datetime.date(2019,1,1)\n",
    "ultimo_dia_mes_cerrado = datetime.date.today().replace(day=1) - datetime.timedelta(days=1)\n",
    "fecha_fin = ultimo_dia_mes_cerrado\n",
    "formato= \"%Y-%m-%dT%H:%M:%SUTC\"\n",
    "\n",
    "fecha_ini_str = fecha_ini.strftime(formato)\n",
    "fecha_fin_str = fecha_fin.strftime(formato)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-03-31T00:00:00UTC'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fecha_fin_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtenemos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CODIGO:  3129 FECHAS 2019-01-01T00:00:00UTC 2020-03-31T00:00:00UTC\n",
      "OK\n",
      "CODIGO:  3194U FECHAS 2019-01-01T00:00:00UTC 2020-03-31T00:00:00UTC\n",
      "OK\n",
      "CODIGO:  3195 FECHAS 2019-01-01T00:00:00UTC 2020-03-31T00:00:00UTC\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "df_aemet_19 = datos_aemet(cod_estaciones_aemet_19,fecha_ini_str,fecha_fin_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AYUNTAMIENTO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_estaciones_ayunt_19 = df_estaciones.filter(df_estaciones[\"MIDE_CLIMA\"]>0).filter(df_estaciones[\"UTILIZADA_19\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_estaciones_ayunt_19 = [elem[0] for elem in df_estaciones_ayunt_19.select(\"CODIGO_CORTO\").collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['16',\n",
       " '18',\n",
       " '24',\n",
       " '36',\n",
       " '39',\n",
       " '54',\n",
       " '58',\n",
       " '59',\n",
       " '8',\n",
       " '103',\n",
       " '107',\n",
       " '109',\n",
       " '110',\n",
       " '112',\n",
       " '114']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cod_estaciones_ayunt_19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "anos = [2019,2020]\n",
    "urls = [\"https://datos.madrid.es/egob/catalogo/300351-0-meteorologicos-diarios.csv\",\n",
    "        \"https://datos.madrid.es/egob/catalogo/300351-3-meteorologicos-diarios.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pd_read_to_df(url):\n",
    "    pdf = pd.read_csv(url,sep=';')\n",
    "    df = spark.createDataFrame(pdf)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = [pd_read_to_df(urls[i])for i in range(len(anos))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ayunt_19 = lista[0]\n",
    "for i in range(1,len(lista)):\n",
    "    df_ayunt_19=df_ayunt_19.union(lista[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_ayunt_19 = df_ayunt_19.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROVINCIA</th>\n",
       "      <th>MUNICIPIO</th>\n",
       "      <th>ESTACION</th>\n",
       "      <th>MAGNITUD</th>\n",
       "      <th>PUNTO_MUESTREO</th>\n",
       "      <th>ANO</th>\n",
       "      <th>MES</th>\n",
       "      <th>D01</th>\n",
       "      <th>V01</th>\n",
       "      <th>D02</th>\n",
       "      <th>...</th>\n",
       "      <th>D27</th>\n",
       "      <th>V27</th>\n",
       "      <th>D28</th>\n",
       "      <th>V28</th>\n",
       "      <th>D29</th>\n",
       "      <th>V29</th>\n",
       "      <th>D30</th>\n",
       "      <th>V30</th>\n",
       "      <th>D31</th>\n",
       "      <th>V31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>102</td>\n",
       "      <td>81</td>\n",
       "      <td>28079102_81_98</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>0.66</td>\n",
       "      <td>V</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>2.57</td>\n",
       "      <td>V</td>\n",
       "      <td>2.93</td>\n",
       "      <td>V</td>\n",
       "      <td>3.23</td>\n",
       "      <td>V</td>\n",
       "      <td>3.18</td>\n",
       "      <td>V</td>\n",
       "      <td>4.72</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>102</td>\n",
       "      <td>81</td>\n",
       "      <td>28079102_81_98</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>4.32</td>\n",
       "      <td>V</td>\n",
       "      <td>2.98</td>\n",
       "      <td>...</td>\n",
       "      <td>1.36</td>\n",
       "      <td>V</td>\n",
       "      <td>0.97</td>\n",
       "      <td>V</td>\n",
       "      <td>0.00</td>\n",
       "      <td>N</td>\n",
       "      <td>0.00</td>\n",
       "      <td>N</td>\n",
       "      <td>0.00</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>102</td>\n",
       "      <td>81</td>\n",
       "      <td>28079102_81_98</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>1.57</td>\n",
       "      <td>V</td>\n",
       "      <td>1.13</td>\n",
       "      <td>...</td>\n",
       "      <td>1.48</td>\n",
       "      <td>V</td>\n",
       "      <td>1.69</td>\n",
       "      <td>V</td>\n",
       "      <td>2.89</td>\n",
       "      <td>V</td>\n",
       "      <td>1.99</td>\n",
       "      <td>V</td>\n",
       "      <td>1.72</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>102</td>\n",
       "      <td>81</td>\n",
       "      <td>28079102_81_98</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>1.32</td>\n",
       "      <td>V</td>\n",
       "      <td>1.21</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>V</td>\n",
       "      <td>1.82</td>\n",
       "      <td>V</td>\n",
       "      <td>1.97</td>\n",
       "      <td>V</td>\n",
       "      <td>1.84</td>\n",
       "      <td>V</td>\n",
       "      <td>0.00</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>102</td>\n",
       "      <td>81</td>\n",
       "      <td>28079102_81_98</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>2.06</td>\n",
       "      <td>V</td>\n",
       "      <td>2.21</td>\n",
       "      <td>...</td>\n",
       "      <td>1.77</td>\n",
       "      <td>V</td>\n",
       "      <td>3.32</td>\n",
       "      <td>V</td>\n",
       "      <td>3.76</td>\n",
       "      <td>V</td>\n",
       "      <td>3.04</td>\n",
       "      <td>V</td>\n",
       "      <td>1.89</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PROVINCIA  MUNICIPIO  ESTACION  MAGNITUD  PUNTO_MUESTREO   ANO  MES   D01  \\\n",
       "0         28         79       102        81  28079102_81_98  2019    1  0.66   \n",
       "1         28         79       102        81  28079102_81_98  2019    2  4.32   \n",
       "2         28         79       102        81  28079102_81_98  2019    3  1.57   \n",
       "3         28         79       102        81  28079102_81_98  2019    4  1.32   \n",
       "4         28         79       102        81  28079102_81_98  2019    5  2.06   \n",
       "\n",
       "  V01   D02  ...   D27  V27   D28  V28   D29  V29   D30  V30   D31  V31  \n",
       "0   V  1.16  ...  2.57    V  2.93    V  3.23    V  3.18    V  4.72    V  \n",
       "1   V  2.98  ...  1.36    V  0.97    V  0.00    N  0.00    N  0.00    N  \n",
       "2   V  1.13  ...  1.48    V  1.69    V  2.89    V  1.99    V  1.72    V  \n",
       "3   V  1.21  ...  1.00    V  1.82    V  1.97    V  1.84    V  0.00    N  \n",
       "4   V  2.21  ...  1.77    V  3.32    V  3.76    V  3.04    V  1.89    V  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_ayunt_19.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AEMET:\n",
    "    1. Unir ambos dataframes\n",
    "    2. Sacar columnas average para temperatura y presion\n",
    "AYUNT:\n",
    "    1. Filtar solo las estaciones que queremos.\n",
    "    2. Formato (Como en el de estaciones) PIVOT\n",
    "    3. Quedarnos con las columnas que queramos\n",
    "MERGE:\n",
    "    1. Comprobar que el formato de los datos es el mismo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
