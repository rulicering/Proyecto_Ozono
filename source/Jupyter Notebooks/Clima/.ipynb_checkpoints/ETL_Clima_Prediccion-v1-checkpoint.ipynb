{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [o3] - Proyecto Ozono - ETL_Clima_Prediccion  - v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [INFO]\n",
    "    \n",
    "\n",
    "        UTILIZAMOS LOS DATOS DDE PREDICCIONES CLIMATICAS PROPORCIONADOS POR LA AEMET.\n",
    "        RANGO => MADRID CIUDAD 28079\n",
    "        SE EJECUTA A LAS 11:30 PM POR LO TANTO SE COGE COMO DIA MAÑANA\n",
    "       \n",
    "        PRESIÓN SE COPIA DEL DÍA ANTERIOR\n",
    "        PRECIPITACIONES -> SE COGE EL MAX PORCENTAJE DE PROBABILIDAD Y SE LE APLICARÁ UNA CORRELACION\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    0. Inicialización\n",
    "    1. Datos\n",
    "        1.0 ----------------------- AEMET -----------------------\n",
    "            1.0.0 Codegen + API\n",
    "            1.0.1 [FUNCIONES] -  Formateo datos\n",
    "            1.0.2 [FUNCIONES] - Request datos\n",
    "            1.0.3 _______ PREDICCIONES _______\n",
    "                1.0.3.0 Obtenemos los datos\n",
    "\t\t\t\t1.0.3.1 Columnas -> ANO,MES,DIA,FECHAS\n",
    "                1.0.3.2 Direccion del viento a Grados\n",
    "\t\t\t\t1.0.3.3 Rename\n",
    "\t\t\t\t1.0.3.4 Types\n",
    "           \n",
    "    2. Export\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [0] - Inicialización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import swagger_client\n",
    "from swagger_client.rest import ApiException\n",
    "from pprint import pprint\n",
    "import datetime\n",
    "import findspark\n",
    "findspark.init('/home/rulicering/BigData/spark-2.4.5-bin-hadoop2.7')\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import re as reg\n",
    "import json\n",
    "from pyspark.sql.types import StructField,StringType,IntegerType,StructType,FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('clima_prediccion').getOrCreate()\n",
    "spark.sparkContext.setLogLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [1] -  Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = open(\"/home/rulicering/Datos_Proyecto_Ozono/Credenciales/Credenciales.json\")\n",
    "credenciales = json.load(f)\n",
    "AEMET_API_KEY = credenciales[\"aemet\"][\"api_key\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1.0]  ----------------------- AEMET -----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    81 - VELOCIDAD VIENTO\n",
    "    82 - DIR. DE VIENTO\n",
    "    83 - TEMPERATURA \n",
    "    87 - PRESION BARIOMETRICA\n",
    "    89 - PRECIPITACIÓN    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.0.0] - Codegen + API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = swagger_client.Configuration()\n",
    "configuration.api_key['api_key'] = AEMET_API_KEY\n",
    "api_predicciones = swagger_client.PrediccionesEspecificasApi(swagger_client.ApiClient(configuration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.0.1] - [FUNCIONES] -  Formateo datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertir_a_diccionario(raw,inicio,tipo):\n",
    "\n",
    "    #Variables locales\n",
    "    i = inicio\n",
    "    iniciob = -1\n",
    "    \n",
    "    #Dicionarios del tipo {}\n",
    "    diccionario = {}\n",
    "    \n",
    "    #Diccionarios elementos de lista\n",
    "    lista = []\n",
    "    \n",
    "    #Auxiliares\n",
    "    final = len(raw)\n",
    "    # A (key) no se vuelve a leer hasta que tenga un value (problemas->\"2020:01:01T19:00:01\")\n",
    "    a_is_fixed = False \n",
    "    \n",
    "    while i < final:\n",
    "        c = raw[i] #Caracter a leer\n",
    "        if(i > 0):c_ant = raw[i-1] # Caracter anterior\n",
    "            \n",
    "        if((c == \":\") & ~(a_is_fixed)):\n",
    "            a_is_fixed = True\n",
    "            a = raw[inicio:i]\n",
    "            iniciob = i+1\n",
    "            b = ''\n",
    "            \n",
    "        if(c == \";\" or c == \",\" ):\n",
    "            #Si estamos en una lista apilamos el diccionario recien leido\n",
    "            if(tipo == 2): lista.append(diccionario)\n",
    "            # Si no, 3 opciones: Lo anterior sea una lista,un diccionario o un valor literal.\n",
    "            else:\n",
    "                a_is_fixed = False\n",
    "                if(c_ant != \"]\")&(c_ant != \"}\"): #Para el valor literal, simplemente lo leemos\n",
    "                    b = raw[iniciob:i]\n",
    "                diccionario[a] =  b #Para lista y diccionario cogemos b que ya guarda ese objeto\n",
    "                inicio = i+1 #Siempre movemos el puntero inicio para que pueda leer otra key\n",
    "                \n",
    "        if(c ==\"{\"):\n",
    "            b,i = convertir_a_diccionario(raw,i+1,1)\n",
    "            \n",
    "            if(tipo != 2): #Si no estamos en una lista, añadimos el nuevo diccionario\n",
    "                diccionario[a]=b\n",
    "            else: #Si estamos en una lista, este es un elemento de ella.\n",
    "                diccionario  = b\n",
    "            inicio = i\n",
    "            a_is_fixed = False\n",
    "            \n",
    "        if(c ==\"}\"):\n",
    "            if(c_ant != \"]\")&(c_ant != \"}\"): #Si era una lista el elemento no se cogen los literales\n",
    "                b = raw[iniciob:i]\n",
    "            diccionario[a] = b\n",
    "            return diccionario, i\n",
    "        \n",
    "        if(c == '['):\n",
    "            b,i = convertir_a_diccionario(raw,i+1,2)\n",
    "            inicio = i\n",
    "            a_is_fixed = False\n",
    "            \n",
    "        if(c == ']'):\n",
    "            lista.append(diccionario)\n",
    "            return lista, i\n",
    "            \n",
    "        i+=1\n",
    "    return diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dic_to_df(dic):\n",
    "    \n",
    "    mañana = (datetime.date.today()+datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "    #Sacamos los datos de hoy\n",
    "    i_dia = -1\n",
    "    for i in range(len(dic[\"prediccion\"][\"dia\"])):\n",
    "        fecha = dic[\"prediccion\"][\"dia\"][i][\"fecha\"][:10]\n",
    "        if(fecha == mañana):\n",
    "            i_dia = i\n",
    "            break\n",
    "    datos = dic[\"prediccion\"][\"dia\"][i_dia]\n",
    "    \n",
    "    #Viento & Direccion\n",
    "    #Periodos de 6 horas\n",
    "    # Hacemos la media para la velocidad y cogemos la direccion del periodo de mayor velocidad\n",
    "    count = 0\n",
    "    agg = 0\n",
    "    direccion = ''\n",
    "    max_velocidad = -1\n",
    "    for elem in datos[\"viento\"]:\n",
    "        hora_ini, hora_fin = elem[\"periodo\"].split(\"-\")\n",
    "        velocidad = int(elem[\"velocidad\"])\n",
    "        if(int(hora_fin)-int(hora_ini)) <=6:\n",
    "            count +=1\n",
    "            agg+= velocidad\n",
    "            if(velocidad > max_velocidad):\n",
    "                max_velocidad = velocidad\n",
    "                direccion = elem[\"direccion\"]\n",
    "    viento = agg/count\n",
    "    \n",
    "    #Temperatura\n",
    "    #Periodos de 6 horas, hacemos la media\n",
    "    count = 0\n",
    "    agg = 0\n",
    "    for elem in datos[\"temperatura\"][\"dato\"]:\n",
    "        count +=1\n",
    "        agg+= int(elem[\"value\"])\n",
    "    temp = agg/count\n",
    "    \n",
    "    #Prob-Precipitacion\n",
    "    # Periodos de 6 horas - Cogemos el valor máximo\n",
    "    count = 0\n",
    "    agg = 0\n",
    "    max_probabilidad = 0.0\n",
    "    for elem in datos[\"probPrecipitacion\"]:\n",
    "        hora_ini, hora_fin = elem[\"periodo\"].split(\"-\")\n",
    "        probabilidad = int(elem[\"value\"])\n",
    "        if(int(hora_fin)-int(hora_ini)) <=6:\n",
    "            if(probabilidad > max_probabilidad):\n",
    "                max_probabilidad= probabilidad\n",
    "    \n",
    "    diccionarios = []\n",
    "    diccionarios.append({\"FECHA\" : mañana,\"VIENTO\" : viento,\"DIRECCION\" : direccion,\n",
    "                        \"TEMPERATURA\" : temp , \"PRESION\": -1.0,\n",
    "                        \"PROBPRECIPITACION\" : float(max_probabilidad)})\n",
    "\n",
    "    # Schema for the new DF\n",
    "    data_schema = [StructField('FECHA',StringType(), True), #Tercer argumento = nullable\n",
    "                   StructField('VIENTO', FloatType(), True),\n",
    "                   StructField('DIRECCION', StringType(), True),\n",
    "                   StructField('TEMPERATURA', FloatType(), True),\n",
    "                   StructField('PRESION', FloatType(), True),\n",
    "                   StructField('PROBPRECIPITACION', FloatType(), True)\n",
    "                  ]\n",
    "    \n",
    "    return spark.createDataFrame(diccionarios,schema = StructType(data_schema)) \n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_sparkdf(data):\n",
    "    #Encoding \"ISO-8859\"\n",
    "    data_v = data.decode(encoding ='ISO-8859-15')\n",
    "    data_v0 = data_v\n",
    "    \n",
    "    # Clean the data\n",
    "    # Step 0 - Acotamos final e inicio\n",
    "    for i in range(50):\n",
    "        if(data_v0[i]=='{'):\n",
    "            data_v0 = data_v0[i+1:]\n",
    "            break\n",
    "    for i in range(50):\n",
    "        if(data_v0[-i]=='}'):\n",
    "            data_v0 = data_v0[:-i]   \n",
    "            break\n",
    "            \n",
    "    # Step 1 - Saltos de linea    \n",
    "    data_v1 = data_v0\n",
    "    data_v1 = data_v1.replace(\"\\n\", \"\")\n",
    "    \n",
    "    # Step 2 - Evitar problemas -> };\n",
    "    data_v2 = data_v1.replace(\"},\",\"};\")\n",
    "    \n",
    "    # Step 3 - Espacios en blanco\n",
    "    patron =['\\s','\\s\"','\"\\s','\\s{',':/']\n",
    "    replace = ['','\"','\"','{','/']\n",
    "    \n",
    "    data_v3 = data_v2\n",
    "    for i in range(len(patron)):\n",
    "        data_v3 = reg.sub(patron[i],replace[i],data_v3)\n",
    "\n",
    "    # Step 4 - Separadores -> ;\n",
    "    data_v4 = data_v3.replace(\"\\\",\\\"\",\"\\\";\\\"\")\n",
    "    \n",
    "    #Step 5 - Comillas\n",
    "    data_clean = data_v4.replace(\"\\\"\", \"\")\n",
    "\n",
    "    diccionario = convertir_a_diccionario(data_clean,0,0)\n",
    "    \n",
    "    #Sacamos los datos que queremos\n",
    "    return dic_to_df(diccionario)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.0.2]  [FUNCIONES] - Request datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def req_to_df(codigo):\n",
    "    print(\"PREDICCIONES ZONA: \", codigo)\n",
    "    try:\n",
    "        api_response = api_predicciones.prediccin_por_municipios_diaria__tiempo_actual_(codigo)\n",
    "        pprint(api_response)\n",
    "    except ApiException as e:\n",
    "        print(\"Exception: %s\\n\" % e)\n",
    "    r = requests.get(api_response.datos)\n",
    "    data = r.content\n",
    "    df_aemet = data_to_sparkdf(data)\n",
    "    print (\"OK\")\n",
    "    return df_aemet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datos_predicciones_aemet(codigos_zonas):\n",
    "    lista_df =[]\n",
    "    for codigo in codigos_zonas:\n",
    "        lista_df.append(req_to_df(codigo))\n",
    "    #Unimos\n",
    "    df = lista_df[0]\n",
    "    for i in range(1,len(lista_df)):\n",
    "        df = df.union(lista_df[i])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.0.3]  _______ PREDICCIONES _______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [1.0.3.0] -  Obtenemos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Código zona MADRID CIUDAD\n",
    "codigos_zonas = [\"28079\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICCIONES ZONA:  28079\n",
      "{'datos': 'https://opendata.aemet.es/opendata/sh/9d6d6971',\n",
      " 'descripcion': 'exito',\n",
      " 'estado': 200,\n",
      " 'metadatos': 'https://opendata.aemet.es/opendata/sh/dfd88b22'}\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "df_predicciones = datos_predicciones_aemet(codigos_zonas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+---------+-----------+-------+-----------------+\n",
      "|     FECHA|VIENTO|DIRECCION|TEMPERATURA|PRESION|PROBPRECIPITACION|\n",
      "+----------+------+---------+-----------+-------+-----------------+\n",
      "|2020-05-22|  8.75|       NE|      25.25|   -1.0|              0.0|\n",
      "+----------+------+---------+-----------+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_predicciones.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [1.0.3.1] -Columnas -> ANO,MES,DIA,FECHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicciones = df_predicciones.withColumn(\"ANO\",df_predicciones[\"FECHA\"][0:4])\n",
    "df_predicciones = df_predicciones.withColumn(\"MES\",df_predicciones[\"FECHA\"][6:2])\n",
    "df_predicciones = df_predicciones.withColumn(\"DIA\",df_predicciones[\"FECHA\"][9:2])\n",
    "df_predicciones = df_predicciones.withColumn(\"FECHA\",F.concat(df_predicciones[\"FECHA\"][0:4],df_predicciones[\"FECHA\"][6:2],df_predicciones[\"FECHA\"][9:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [1.0.3.2] - Direccion viento -> Grados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dir_to_grad(direccion):\n",
    "    if(direccion == 'E'): return 0\n",
    "    if(direccion == 'NE'): return 45\n",
    "    if(direccion == 'N'): return 90\n",
    "    if(direccion == 'NO'): return 135\n",
    "    if(direccion == 'O'): return 180\n",
    "    if(direccion == 'SO'): return 225\n",
    "    if(direccion == 'S'): return 270\n",
    "    if(direccion == 'SE'): return 315\n",
    "    if(direccion == 'C'): return None    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_udf = F.udf(lambda x: dir_to_grad(x),IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_predicciones = df_predicciones.withColumn(\"DIRECCION\",my_udf(df_predicciones[\"DIRECCION\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [1.0.3.3] - Rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_predicciones = df_predicciones.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_predicciones =pd_predicciones.rename(columns={ \"VIENTO\":\"81\",                         \n",
    "                                                   \"DIRECCION\":\"82\",\n",
    "                                                   \"TEMPERATURA\":\"83\",     \n",
    "                                                   \"PRESION\":\"87\",\n",
    "                                                   \"PROBPRECIPITACION\":\"%89\",\n",
    "                                             })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [1.0.3.4] - Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_predicciones[\"ANO\"] =pd_predicciones[\"ANO\"].astype(int)\n",
    "pd_predicciones[\"MES\"] =pd_predicciones[\"MES\"].astype(int)\n",
    "pd_predicciones[\"DIA\"] =pd_predicciones[\"DIA\"].astype(int)\n",
    "pd_predicciones[\"FECHA\"] =pd_predicciones[\"FECHA\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [2] - Formato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = pd_predicciones.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = cols[0:1]+ cols[-3:] + cols[1:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_predicciones = pd_predicciones[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [3] -Export\n",
    "    La prediccion para MAÑANA, se ejecuta a las 11:50 PM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_final = pd_predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevo = (datetime.date.today() + datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "anterior = datetime.date.today().strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BackUp\n",
    "pd_final.to_csv(\"/home/rulicering/Datos_Proyecto_Ozono/Procesado/Clima/BackUp/Clima_Prediccion-\"+ nuevo + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] - Clima_Prediccion- 2020-05-22 .csv --- Created successfully\n"
     ]
    }
   ],
   "source": [
    "pd_final.to_csv(\"/home/rulicering/Datos_Proyecto_Ozono/Procesado/Clima/Clima_Prediccion-\"+ nuevo + \".csv\")\n",
    "print(\"[INFO] - Clima_Prediccion-\", nuevo ,\".csv --- Created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] - Clima_Prediccion- 2020-05-21 .csv --- Could not been removed\n"
     ]
    }
   ],
   "source": [
    "#Borrar la de ayer\n",
    "try:\n",
    "    os.remove(\"/home/rulicering/Datos_Proyecto_Ozono/Procesado/Clima/Clima_Prediccion-\"+ anterior + \".csv\")\n",
    "    print(\"[INFO] - Clima_Prediccion-\", anterior,\".csv --- Removed successfully\")\n",
    "except:\n",
    "    print(\"[ERROR] - Clima_Prediccion-\", anterior,\".csv --- Could not been removed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
